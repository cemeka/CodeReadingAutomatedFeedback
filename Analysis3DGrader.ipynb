{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adverse-gauge",
   "metadata": {},
   "source": [
    "Script serves two purposes:\n",
    "Curates data for 3d grader\n",
    "Builds models for grading EiPE answers (Data is 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "indoor-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\chine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "subjective-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"3d_label_fullset_merged.csv\"\n",
    "alldata_df = pd.read_csv(data_file, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distant-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#generate the final labels for the 3d grader - currently done based on majority grade\n",
    "unambig = []\n",
    "corr = []\n",
    "high_lvl = []\n",
    "majority_3d_labels = []\n",
    "\n",
    "def get_final_vote(person1label, person2label, person3label):\n",
    "    labels = [person1label, person2label, person3label]\n",
    "    num_zero_labels = labels.count(0)\n",
    "    num_one_labels = labels.count(1)\n",
    "    \n",
    "    if num_zero_labels > num_one_labels:\n",
    "        return 0\n",
    "    elif num_one_labels > num_zero_labels:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "for index, row in alldata_df.iterrows():\n",
    "    \n",
    "    majority_unambig = get_final_vote(row[\"max_una\"], row[\"chinny_una\"], row[\"binglin_una\"])\n",
    "    majority_correct = get_final_vote(row[\"max_c\"], row[\"chinny_c\"], row[\"binglin_c\"])\n",
    "    majority_highlvl = get_final_vote(row[\"max_hl\"], row[\"chinny_hl\"], row[\"binglin_hl\"])\n",
    "    \n",
    "    if majority_unambig == -1 or majority_correct == -1 or majority_highlvl == -1: #something wrong with data\n",
    "        print(\"Could not reconcile row {}\".format(index))\n",
    "    else:\n",
    "        majority_3d_labels.append((majority_unambig, majority_correct, majority_highlvl)) #store the data in other format\n",
    "    \n",
    "    unambig.append(majority_unambig)\n",
    "    corr.append(majority_correct)\n",
    "    high_lvl.append(majority_highlvl)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "alldata_df[\"majority_una\"] = pd.Series(unambig)\n",
    "alldata_df[\"majority_c\"]   = pd.Series(corr)\n",
    "alldata_df[\"majority_hl\"]  = pd.Series(high_lvl)\n",
    "\n",
    "\n",
    "qids = alldata_df[\"qid\"].unique()\n",
    "\n",
    "alldata_df.to_csv(path_or_buf = \"majority_vote_added.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ultimate-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one human grader matched the majority vote 99.5% of the time\n",
      "At least two human graders matched the majority vote 88.3% of the time\n",
      "All three human graders matched the majority vote 45.7% of the time\n"
     ]
    }
   ],
   "source": [
    "#determine the amount of agreement between the human graders\n",
    "\n",
    "at_least_one_agrees = 0\n",
    "at_least_two_agree = 0\n",
    "at_least_three_agree = 0\n",
    "\n",
    "num_rows_total = 0\n",
    "\n",
    "        \n",
    "\n",
    "for index, row in alldata_df.iterrows():\n",
    "    \n",
    "    num_rows_total += 1\n",
    "    \n",
    "    max_labels = (row[\"max_una\"], row[\"max_c\"], row[\"max_hl\"])\n",
    "    chinny_labels = (row[\"chinny_una\"], row[\"chinny_c\"], row[\"chinny_hl\"])\n",
    "    binglin_labels = (row[\"binglin_una\"], row[\"binglin_c\"], row[\"binglin_hl\"])\n",
    "    \n",
    "    all_human_labels = [max_labels, chinny_labels, binglin_labels]\n",
    "    cur_majority_vote = (row[\"majority_una\"], row[\"majority_c\"], row[\"majority_hl\"])\n",
    "    \n",
    "    if cur_majority_vote in all_human_labels:\n",
    "        at_least_one_agrees += 1\n",
    "        all_human_labels.remove(cur_majority_vote) #removing so we can see if it still exists, i.e. if at least 2 occur.\n",
    "        \n",
    "    if cur_majority_vote in all_human_labels:\n",
    "        at_least_two_agree += 1\n",
    "        all_human_labels.remove(cur_majority_vote)\n",
    "        \n",
    "    if cur_majority_vote in all_human_labels:\n",
    "        at_least_three_agree += 1\n",
    "        \n",
    "\n",
    "\n",
    "print(\"At least one human grader matched the majority vote {}% of the time\".format(100 * round(at_least_one_agrees/num_rows_total, 3)))\n",
    "print(\"At least two human graders matched the majority vote {}% of the time\".format(100 * round(at_least_two_agree/num_rows_total, 3)))\n",
    "print(\"All three human graders matched the majority vote {}% of the time\".format(100 * round(at_least_three_agree/num_rows_total, 3)))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laden-botswana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   5.76% (157)\n",
      "(0, 0, 1)  13.00% (354)\n",
      "(0, 1, 0)   1.25% (34)\n",
      "(0, 1, 1)   9.36% (255)\n",
      "(1, 0, 0)   4.66% (127)\n",
      "(1, 1, 0)   6.61% (180)\n",
      "(1, 0, 1)  20.56% (560)\n",
      "(1, 1, 1)  38.80% (1057)\n"
     ]
    }
   ],
   "source": [
    "buckets = [(0,0,0), (0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,1,0), (1,0,1), (1,1,1)]\n",
    "lendata = len(majority_3d_labels)\n",
    "\n",
    "\n",
    "print(\"3D groupings = (unambig, correct, highlevel)\\n\\n\")\n",
    "print(\"3D label,  Freq. (Num Times Occur)\")\n",
    "\n",
    "\n",
    "for curbucket in buckets:\n",
    "    curcount = majority_3d_labels.count(curbucket) #get the number of occurrences of a particular labeling configuration within the data\n",
    "    print(\"{}  {:>5.2f}% ({})\".format(curbucket, round(100*curcount/lendata, 2), curcount)) #print group name, group freq and raw count of group occur.\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def display_class_dist(given_df):\n",
    "    '''\n",
    "    Display the distribution of data for each qid. There are 8 possible bins.\n",
    "    '''\n",
    "    classes =  {(0,0,0): 0, (0,0,1):0, (0,1,0):0, (0,1,1):0, \n",
    "                (1,0,0):0, (1,1,0):0, (1,0,1):0, (1,1,1):0}\n",
    "    \n",
    "    ordering = [(0,0,0), (0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,1,0), (1,0,1), (1,1,1)]\n",
    "    \n",
    "    print(\"3D groupings = (unambig, correct, highlevel)\\n\\n\")\n",
    "    print(\"3D label,  Freq. (Num Times Occur)\")\n",
    "    \n",
    "    numrowsdata = 0\n",
    "    \n",
    "    for index, row in practicequiz_df.iterrows():\n",
    "        \n",
    "        cur_unambig = row[\"majority_una\"]\n",
    "        cur_correct = row[\"majority_c\"]\n",
    "        cur_hl      = row[\"majority_hl\"]\n",
    "        \n",
    "        classes[(cur_unambig, cur_correct, cur_hl)] += 1\n",
    "        numrowsdata += 1\n",
    "    \n",
    "    for curbin in ordering:\n",
    "        curbincount = classes[curbin] #get the number of occurrences of a particular labeling configuration within the data\n",
    "        print(\"{}  {:>5.2f}% ({})\".format(curbincount, round(100*curbincount/numsrowsdata, 2), curbincount)) #print group name, group freq and raw count of group occur.\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "turkish-concrete",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl_qid</th>\n",
       "      <th>qid</th>\n",
       "      <th>code</th>\n",
       "      <th>assumption</th>\n",
       "      <th>example_correct_answers</th>\n",
       "      <th>response</th>\n",
       "      <th>max_una</th>\n",
       "      <th>max_c</th>\n",
       "      <th>max_hl</th>\n",
       "      <th>chinny_una</th>\n",
       "      <th>chinny_c</th>\n",
       "      <th>chinny_hl</th>\n",
       "      <th>binglin_una</th>\n",
       "      <th>binglin_c</th>\n",
       "      <th>binglin_hl</th>\n",
       "      <th>majority_una</th>\n",
       "      <th>majority_c</th>\n",
       "      <th>majority_hl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdrd_exam2_manual/cdrd_exam2_1</td>\n",
       "      <td>return the location of an element if it is in ...</td>\n",
       "      <td>def f(x, y):\\n    if y in x:\\n        return x...</td>\n",
       "      <td>Assume that variable x is a list of strings an...</td>\n",
       "      <td>['Return the position of a given element in a ...</td>\n",
       "      <td>returns the index of a string in a list if it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_combined</td>\n",
       "      <td>print_items_out_smaller_then_larger</td>\n",
       "      <td>def f(x, y):\\n    if x &lt; y:\\n        print(x, ...</td>\n",
       "      <td>Assume that the variables x and y are integers.</td>\n",
       "      <td>['prints two given numbers in numberical order...</td>\n",
       "      <td>Prints lesser number then greater number</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdrd_final_manual/cdrd_final_1</td>\n",
       "      <td>find_largest_number_in_file</td>\n",
       "      <td>def f(x):\\n    l = open(x).readlines()\\n    n ...</td>\n",
       "      <td>Assume that the variable x is a string contain...</td>\n",
       "      <td>['Return the largest number from a given file'...</td>\n",
       "      <td>returns n if less than or equal to i</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdrd_final_manual/cdrd_final_2</td>\n",
       "      <td>a33_replace_all_ys_with_zs</td>\n",
       "      <td>def f(x, y, z):\\n    for i in range(len(x)):\\n...</td>\n",
       "      <td>Assume that the variable x is a list of intege...</td>\n",
       "      <td>['Replace every element equal to y in the give...</td>\n",
       "      <td>if a value in list x is equal to y, value is c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdrd_exam2_manual/cdrd_exam2_2</td>\n",
       "      <td>increase_all_numbers_by_y</td>\n",
       "      <td>def f(x,y):\\n    for k in range(len(x)):\\n    ...</td>\n",
       "      <td>Assume that the variable x is a list of number...</td>\n",
       "      <td>['Given a list and a number, increase every el...</td>\n",
       "      <td>add y to each number of a list</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  pl_qid  \\\n",
       "0         cdrd_exam2_manual/cdrd_exam2_1   \n",
       "1  cdrd_exam1_manual/cdrd_exam1_combined   \n",
       "2         cdrd_final_manual/cdrd_final_1   \n",
       "3         cdrd_final_manual/cdrd_final_2   \n",
       "4         cdrd_exam2_manual/cdrd_exam2_2   \n",
       "\n",
       "                                                 qid  \\\n",
       "0  return the location of an element if it is in ...   \n",
       "1                print_items_out_smaller_then_larger   \n",
       "2                        find_largest_number_in_file   \n",
       "3                         a33_replace_all_ys_with_zs   \n",
       "4                          increase_all_numbers_by_y   \n",
       "\n",
       "                                                code  \\\n",
       "0  def f(x, y):\\n    if y in x:\\n        return x...   \n",
       "1  def f(x, y):\\n    if x < y:\\n        print(x, ...   \n",
       "2  def f(x):\\n    l = open(x).readlines()\\n    n ...   \n",
       "3  def f(x, y, z):\\n    for i in range(len(x)):\\n...   \n",
       "4  def f(x,y):\\n    for k in range(len(x)):\\n    ...   \n",
       "\n",
       "                                          assumption  \\\n",
       "0  Assume that variable x is a list of strings an...   \n",
       "1    Assume that the variables x and y are integers.   \n",
       "2  Assume that the variable x is a string contain...   \n",
       "3  Assume that the variable x is a list of intege...   \n",
       "4  Assume that the variable x is a list of number...   \n",
       "\n",
       "                             example_correct_answers  \\\n",
       "0  ['Return the position of a given element in a ...   \n",
       "1  ['prints two given numbers in numberical order...   \n",
       "2  ['Return the largest number from a given file'...   \n",
       "3  ['Replace every element equal to y in the give...   \n",
       "4  ['Given a list and a number, increase every el...   \n",
       "\n",
       "                                            response  max_una  max_c  max_hl  \\\n",
       "0  returns the index of a string in a list if it ...        0      1       1   \n",
       "1           Prints lesser number then greater number        0      1       1   \n",
       "2               returns n if less than or equal to i        1      0       0   \n",
       "3  if a value in list x is equal to y, value is c...        0      1       1   \n",
       "4                     add y to each number of a list        1      1       1   \n",
       "\n",
       "   chinny_una  chinny_c  chinny_hl  binglin_una  binglin_c  binglin_hl  \\\n",
       "0           0         1        1.0            1          0           1   \n",
       "1           1         1        1.0            1          1           1   \n",
       "2           1         0        0.0            0          0           0   \n",
       "3           1         1        1.0            0          1           1   \n",
       "4           1         1        1.0            1          1           1   \n",
       "\n",
       "   majority_una  majority_c  majority_hl  \n",
       "0             0           1            1  \n",
       "1             1           1            1  \n",
       "2             1           0            0  \n",
       "3             0           1            1  \n",
       "4             1           1            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview of the data\n",
    "alldata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocational-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(studentresponse):    \n",
    "    words = word_tokenize(studentresponse)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    lower_words= [word.lower() for word in stemmed_words] #convert to lowercase\n",
    "    stemmed_words = lower_words\n",
    "    regular_alpha = [] \n",
    "    for word in stemmed_words:\n",
    "        if word.isalnum():  #remove any word that isn't an alphabet or a number.\n",
    "            regular_alpha.append(word)\n",
    "    stemmed_words = regular_alpha\n",
    "    \n",
    "    #TODO - need to handle stop words by passing in my own list. (related to tf-idf weighting)\n",
    "    \n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "continuing-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, what_to_predict, accuracy ):\n",
    "        '''\n",
    "        Function to help with plotting a confusion matrix\n",
    "        '''\n",
    "        plt.figure(figsize=(9,9))\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "        plt.ylabel('Actual label');\n",
    "        plt.xlabel('Predicted label');\n",
    "        all_sample_title = 'Accuracy Score for {thingtopredict}: {accscore:.2f}'.format(thingtopredict = what_to_predict,\n",
    "                                                                                    accscore = accuracy)\n",
    "        plt.title(all_sample_title, size = 15);\n",
    "        \n",
    "\n",
    "def create_input_representation(given_df, pct_for_train = 0.8, display_model_info = False):\n",
    "    numsamples = 0\n",
    "    processed_studentanswers = []\n",
    "    \n",
    "    for studentanswer in given_df[\"response\"]:\n",
    "    \n",
    "        processed_answer = preprocess_text(studentanswer)\n",
    "        processed_studentanswers.append(processed_answer)\n",
    "        numsamples +=  1\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2), min_df = 2) \n",
    "    \n",
    "    #fit only on training data to prevent overfit\n",
    "    vec_fitter = vectorizer.fit(processed_studentanswers[:int(numsamples *  pct_for_train)])\n",
    "    bag_of_words_and_bigrams = vec_fitter.transform(processed_studentanswers)\n",
    "    \n",
    "    if display_model_info:\n",
    "        print(\"Unique words in vocab = \", vectorizer.get_feature_names())\n",
    "        print(\"\\n\\nShape of processed input vector = \", bag_of_words_and_bigrams.shape)\n",
    "        print(\"\\n\\nVocab and indices = \", vectorizer.vocabulary_)#indices of each word\n",
    "        \n",
    "    return bag_of_words_and_bigrams.toarray()\n",
    "\n",
    "def split_data_and_train(given_Xdf, given_ydf, given_train_pct, qname = \"\"):\n",
    "    \n",
    "    num_set_samples = given_Xdf.shape[0]\n",
    "    divider = int(num_set_samples * given_train_pct)\n",
    "    \n",
    "    X_train = given_Xdf[0: divider, ]\n",
    "    y_train = given_ydf[0: divider, ]\n",
    "    \n",
    "    X_test = given_Xdf[divider: , ]\n",
    "    y_test = given_ydf[divider: , ]\n",
    "    \n",
    "    \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "    #NOTE: Order for data is [unambig, correct, high level]\n",
    "    for i in range(3):\n",
    "       \n",
    "        # using standard log. regression model\n",
    "        model = LogisticRegression(random_state=0)\n",
    "        model = model.fit(X_train, y_train[:,i]) #train only one column at a time\n",
    "    \n",
    "\n",
    "        binary_y_predictions =  model.predict(X_test)\n",
    "        #use the withheld set for testing the model\n",
    "        print(\"{} Log reg. model performance on the withheld test set:\\n\\n\".format(labels_order[i]))\n",
    "        \n",
    "        #for the y_test data (the true labels for column i), check if the predictions match\n",
    "        dim_accuracy = metrics.accuracy_score(y_test[:, i], binary_y_predictions)\n",
    "        print(\"Accuracy is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        #print(metrics.classification_report(y_test, binary_y_predictions))\n",
    "\n",
    "\n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_test[:, i],binary_y_predictions, normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    return accuracy_l #accuracy for the three dimensions for a given problem\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "informed-seafood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID = 'return the location of an element if it is in the list.' Amount of labeled data = 295 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5932203389830508\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.04545455 0.95454545]\n",
      " [0.08108108 0.91891892]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.864406779661017\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.85185185 0.14814815]\n",
      " [0.125      0.875     ]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  1.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'print_items_out_smaller_then_larger.' Amount of labeled data = 466 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6276595744680851\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.14814815 0.85185185]\n",
      " [0.17910448 0.82089552]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.723404255319149\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.42424242 0.57575758]\n",
      " [0.1147541  0.8852459 ]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8723404255319149\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.6 0.4]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'find_largest_number_in_file.' Amount of labeled data = 327 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8484848484848485\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.45454545 0.54545455]\n",
      " [0.07272727 0.92727273]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9696969696969697\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.         0.        ]\n",
      " [0.05263158 0.94736842]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8333333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.27272727 0.72727273]\n",
      " [0.05454545 0.94545455]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'a33_replace_all_ys_with_zs.' Amount of labeled data = 249 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.78\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.81481481 0.18518519]\n",
      " [0.26086957 0.73913043]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.88\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.85714286 0.14285714]\n",
      " [0.10344828 0.89655172]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.88\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.04545455 0.95454545]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'increase_all_numbers_by_y.' Amount of labeled data = 88 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6666666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.75       0.25      ]\n",
      " [0.35714286 0.64285714]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8888888888888888\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.         0.        ]\n",
      " [0.22222222 0.77777778]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8333333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.6        0.4       ]\n",
      " [0.07692308 0.92307692]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'count how many times a given string appears in a list regardless of case.' Amount of labeled data = 99 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.25 0.75]\n",
      " [0.   1.  ]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8 0.2]\n",
      " [1.  0. ]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.95\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'swaps_first_and_last.' Amount of labeled data = 209 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8095238095238095\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.3     0.7    ]\n",
      " [0.03125 0.96875]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8571428571428571\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.91666667 0.08333333]\n",
      " [0.22222222 0.77777778]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7619047619047619\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.70588235 0.29411765]\n",
      " [0.2        0.8       ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'print_found_if_three_numbers_unique.' Amount of labeled data = 141 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6206896551724138\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.18181818 0.81818182]\n",
      " [0.11111111 0.88888889]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8275862068965517\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.2        0.8       ]\n",
      " [0.04166667 0.95833333]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  1.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'return whether strings start with the same letter.' Amount of labeled data = 122 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.76\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.4  0.6 ]\n",
      " [0.15 0.85]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.88\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.         0.        ]\n",
      " [0.17647059 0.82352941]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.92\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'does_list_have_value_above_y.' Amount of labeled data = 56 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5833333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.625 0.375]\n",
      " [0.5   0.5  ]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8333333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5 0.5]\n",
      " [0.1 0.9]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9166666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'computes_average_of_list.' Amount of labeled data = 100 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  1.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  1.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.95\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.91666667 0.08333333]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'count how many numbers in a list are multiples of another number.' Amount of labeled data = 149 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.25       0.75      ]\n",
      " [0.13636364 0.86363636]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.45454545 0.54545455]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8666666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5 0.5]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'split a csv string and return the nth word.' Amount of labeled data = 132 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7777777777777778\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.6        0.4       ]\n",
      " [0.18181818 0.81818182]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8888888888888888\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.89473684 0.10526316]\n",
      " [0.125      0.875     ]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  1.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'make_list_from_zero_to_x.' Amount of labeled data = 110 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.57142857 0.42857143]\n",
      " [0.625      0.375     ]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8636363636363636\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.         0.        ]\n",
      " [0.33333333 0.66666667]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5454545454545454\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.375      0.625     ]\n",
      " [0.35714286 0.64285714]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'list_copy_up_to_positive.' Amount of labeled data = 76 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5625\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.         1.        ]\n",
      " [0.35714286 0.64285714]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8125\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.  0. ]\n",
      " [0.5 0.5]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9375\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'absolute_value.' Amount of labeled data = 57 samples\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6666666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.25  0.75 ]\n",
      " [0.125 0.875]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8        0.2       ]\n",
      " [0.28571429 0.71428571]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9166666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'is_even.' Amount of labeled data = 48 samples\n",
      "\n",
      "\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.   1.  ]\n",
      " [0.25 0.75]]\n",
      "\n",
      "\n",
      "\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.14285714 0.85714286]]\n",
      "\n",
      "\n",
      "\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for each question, create the input representation\n",
    "#train various models, bigrams, bigrams + distance_from_golden, report on performance\n",
    "\n",
    "train_pct = 0.8\n",
    "qids_accuracy = []\n",
    "\n",
    "for cur_qid in qids:\n",
    "    \n",
    "    cur_question_df = alldata_df[alldata_df[\"qid\"] == cur_qid]\n",
    "    print(\"QID = \\'{}.\\' Amount of labeled data = {} samples\\n\\n\".format(cur_qid, cur_question_df.shape[0]))\n",
    "    X = create_input_representation(cur_question_df, pct_for_train = train_pct, display_model_info = False)\n",
    "    y = cur_question_df[[\"majority_una\", \"majority_c\", \"majority_hl\"]]\n",
    "    y = y.to_numpy(dtype=int)\n",
    "\n",
    "    qname_formatted = \": \" + cur_qid #format cur_qid name so it looks nice when printed with other function\n",
    "    cur_qid_accuracy = split_data_and_train(X, y, train_pct, qname = qname_formatted) \n",
    "    qids_accuracy.append(cur_qid_accuracy)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "supreme-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging results for all qids in each of the respective dimensions\n",
      "\n",
      "Avg accuracy for Unambig: 0.69\n",
      "Avg accuracy for Correct column: 0.84\n",
      "Avg accuracy for High-level column: 0.89\n",
      "\n",
      "\n",
      "Average results across all dimensions for all qids: 0.81\n"
     ]
    }
   ],
   "source": [
    "#show the accuracy of the classifier for each column across all data\n",
    "\n",
    "\n",
    "\n",
    "qids_accuracy = np.array(qids_accuracy)\n",
    "print(\"Averaging results for all qids in each of the respective dimensions\\n\")\n",
    "\n",
    "avg_unambig_accuracy = np.mean(qids_accuracy[:, 0])\n",
    "print(\"Avg accuracy for Unambig: {:.2f}\".format(avg_unambig_accuracy))\n",
    "\n",
    "\n",
    "avg_corr_accuracy = np.mean(qids_accuracy[:, 1])\n",
    "print(\"Avg accuracy for Correct column: {:.2f}\".format(avg_corr_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "avg_highlvl_accuracy = np.mean(qids_accuracy[:, 2])\n",
    "print(\"Avg accuracy for High-level column: {:.2f}\\n\\n\".format(avg_highlvl_accuracy))\n",
    "\n",
    "\n",
    "avg_classifier_perf_overall = np.mean(qids_accuracy)\n",
    "print(\"Average results across all dimensions for all qids: {:.2f}\".format(avg_classifier_perf_overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-accident",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
