{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adverse-gauge",
   "metadata": {},
   "source": [
    "Script serves two purposes:\n",
    "Curates data for 3d grader\n",
    "Builds models for grading EiPE answers (Data is 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "indoor-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\chine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "subjective-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"sigcse_2024.csv\"\n",
    "alldata_df = pd.read_csv(data_file, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "objective-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>embedding_subset</th>\n",
       "      <th>embedding_index</th>\n",
       "      <th>pl_qid</th>\n",
       "      <th>qid</th>\n",
       "      <th>code</th>\n",
       "      <th>assumption</th>\n",
       "      <th>example_correct_answers</th>\n",
       "      <th>response</th>\n",
       "      <th>binary_annotators</th>\n",
       "      <th>...</th>\n",
       "      <th>chinny_una</th>\n",
       "      <th>chinny_c</th>\n",
       "      <th>chinny_hl</th>\n",
       "      <th>binglin_una</th>\n",
       "      <th>binglin_c</th>\n",
       "      <th>binglin_hl</th>\n",
       "      <th>una</th>\n",
       "      <th>c</th>\n",
       "      <th>hl</th>\n",
       "      <th>3d_resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>97</td>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_1</td>\n",
       "      <td>print_found_if_three_numbers_unique</td>\n",
       "      <td>def f(x, y, z):\\n    if x != y and x != z and ...</td>\n",
       "      <td>Assume that the variables x, y, and z are inte...</td>\n",
       "      <td>['Print the word found if all three numbers ar...</td>\n",
       "      <td>the code checks if all arguments regarding var...</td>\n",
       "      <td>['Austin', 'Max']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate</td>\n",
       "      <td>train</td>\n",
       "      <td>113</td>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_1</td>\n",
       "      <td>print_items_out_smaller_then_larger</td>\n",
       "      <td>def f(x, y):\\n    if x &lt; y:\\n        print(x, ...</td>\n",
       "      <td>Assume that the variables x and y are integers.</td>\n",
       "      <td>['prints two given numbers in numberical order...</td>\n",
       "      <td>prints two numbers ordered smallest to largest</td>\n",
       "      <td>['Austin', 'Max']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>138</td>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_2</td>\n",
       "      <td>computes_average_of_list</td>\n",
       "      <td>def f(x):\\n    return sum(x) / len(x)</td>\n",
       "      <td>Assume that the variable x is a non-empty list...</td>\n",
       "      <td>['Returns the average value in a list', 'finds...</td>\n",
       "      <td>returns the average of a list</td>\n",
       "      <td>['Binglin', 'Rachel']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validate</td>\n",
       "      <td>train</td>\n",
       "      <td>150</td>\n",
       "      <td>cdrd_week5_exam</td>\n",
       "      <td>does_list_have_value_above_y</td>\n",
       "      <td>def f(x, y):\\n    for val in x:\\n        if va...</td>\n",
       "      <td>Assume that the variable x is a list of intege...</td>\n",
       "      <td>['Return True if at least one list element is ...</td>\n",
       "      <td>returns whether the first value in a list is g...</td>\n",
       "      <td>['Binglin']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>228</td>\n",
       "      <td>cdrd_exam3_manual/cdrd_exam3_1</td>\n",
       "      <td>count how many times a given string appears in...</td>\n",
       "      <td>def f(x, y):\\n    k = 0\\n    for e in x:\\n    ...</td>\n",
       "      <td>Assume that variable x is a list of strings an...</td>\n",
       "      <td>['Return a count of how many times a given str...</td>\n",
       "      <td>return the number of times in which the string...</td>\n",
       "      <td>['Binglin', 'Rachel']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subset embedding_subset  embedding_index                          pl_qid  \\\n",
       "0     train            train               97  cdrd_exam1_manual/cdrd_exam1_1   \n",
       "1  validate            train              113  cdrd_exam1_manual/cdrd_exam1_1   \n",
       "2     train            train              138  cdrd_exam1_manual/cdrd_exam1_2   \n",
       "3  validate            train              150                 cdrd_week5_exam   \n",
       "4     train            train              228  cdrd_exam3_manual/cdrd_exam3_1   \n",
       "\n",
       "                                                 qid  \\\n",
       "0                print_found_if_three_numbers_unique   \n",
       "1                print_items_out_smaller_then_larger   \n",
       "2                           computes_average_of_list   \n",
       "3                       does_list_have_value_above_y   \n",
       "4  count how many times a given string appears in...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def f(x, y, z):\\n    if x != y and x != z and ...   \n",
       "1  def f(x, y):\\n    if x < y:\\n        print(x, ...   \n",
       "2              def f(x):\\n    return sum(x) / len(x)   \n",
       "3  def f(x, y):\\n    for val in x:\\n        if va...   \n",
       "4  def f(x, y):\\n    k = 0\\n    for e in x:\\n    ...   \n",
       "\n",
       "                                          assumption  \\\n",
       "0  Assume that the variables x, y, and z are inte...   \n",
       "1    Assume that the variables x and y are integers.   \n",
       "2  Assume that the variable x is a non-empty list...   \n",
       "3  Assume that the variable x is a list of intege...   \n",
       "4  Assume that variable x is a list of strings an...   \n",
       "\n",
       "                             example_correct_answers  \\\n",
       "0  ['Print the word found if all three numbers ar...   \n",
       "1  ['prints two given numbers in numberical order...   \n",
       "2  ['Returns the average value in a list', 'finds...   \n",
       "3  ['Return True if at least one list element is ...   \n",
       "4  ['Return a count of how many times a given str...   \n",
       "\n",
       "                                            response      binary_annotators  \\\n",
       "0  the code checks if all arguments regarding var...      ['Austin', 'Max']   \n",
       "1     prints two numbers ordered smallest to largest      ['Austin', 'Max']   \n",
       "2                      returns the average of a list  ['Binglin', 'Rachel']   \n",
       "3  returns whether the first value in a list is g...            ['Binglin']   \n",
       "4  return the number of times in which the string...  ['Binglin', 'Rachel']   \n",
       "\n",
       "   ...  chinny_una  chinny_c  chinny_hl  binglin_una  binglin_c  binglin_hl  \\\n",
       "0  ...           0         0        0.0            0          0           0   \n",
       "1  ...           1         1        1.0            1          1           1   \n",
       "2  ...           1         1        1.0            1          1           1   \n",
       "3  ...           1         0        1.0            1          0           1   \n",
       "4  ...           1         1        0.0            1          1           1   \n",
       "\n",
       "   una  c  hl  3d_resolution  \n",
       "0    1  0   0      reconcile  \n",
       "1    0  1   1      reconcile  \n",
       "2    1  1   1      reconcile  \n",
       "3    1  0   1      reconcile  \n",
       "4    1  1   1      reconcile  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "constant-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 24)\n"
     ]
    }
   ],
   "source": [
    "print(alldata_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "laden-botswana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_class_dist(given_df):\n",
    "    '''\n",
    "    Display the distribution of data for each qid. There are 8 possible bins.\n",
    "    '''\n",
    "    classes =  {(0,0,0): 0, (0,0,1):0, (0,1,0):0, (0,1,1):0, \n",
    "                (1,0,0):0, (1,1,0):0, (1,0,1):0, (1,1,1):0}\n",
    "    \n",
    "    ordering = [(0,0,0), (0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,1,0), (1,0,1), (1,1,1)]\n",
    "    \n",
    "    print(\"3D groupings = (unambig, correct, highlevel)\\n\\n\")\n",
    "    print(\"3D label,  Freq. (Num Times Occur)\")\n",
    "    \n",
    "    numrowsdata = 0\n",
    "    \n",
    "    for index, row in given_df.iterrows():\n",
    "        \n",
    "        cur_unambig = row[\"una\"]\n",
    "        cur_correct = row[\"c\"]\n",
    "        cur_hl      = row[\"hl\"]\n",
    "        \n",
    "        classes[(cur_unambig, cur_correct, cur_hl)] += 1\n",
    "        numrowsdata += 1\n",
    "    \n",
    "    for curbin in ordering:\n",
    "        curbincount = classes[curbin] #get the number of occurrences of a particular labeling configuration within the data\n",
    "        print(\"{}  {:>5.2f}% ({})\".format(curbin, round(100*curbincount/numrowsdata, 2), curbincount)) #print group name, group freq and raw count of group occur.\n",
    "\n",
    "\n",
    "    \n",
    "def qid_dist(given_df):\n",
    "    \"\"\"\n",
    "    Show how frequently each qid occured in the data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "handed-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1832, 24)\n",
      "(72, 24)\n",
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   0.00% (0)\n",
      "(0, 0, 1)   0.00% (0)\n",
      "(0, 1, 0)   0.00% (0)\n",
      "(0, 1, 1)   8.33% (6)\n",
      "(1, 0, 0)   0.00% (0)\n",
      "(1, 1, 0)  44.44% (32)\n",
      "(1, 0, 1)   0.00% (0)\n",
      "(1, 1, 1)  47.22% (34)\n",
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   0.00% (0)\n",
      "(0, 0, 1)   0.00% (0)\n",
      "(0, 1, 0)   0.00% (0)\n",
      "(0, 1, 1)   9.17% (11)\n",
      "(1, 0, 0)   0.83% (1)\n",
      "(1, 1, 0)  42.50% (51)\n",
      "(1, 0, 1)   0.00% (0)\n",
      "(1, 1, 1)  47.50% (57)\n"
     ]
    }
   ],
   "source": [
    "filter1 = alldata_df[alldata_df[\"subset\"] == \"train\"]\n",
    "print(filter1.shape)\n",
    "filter2= filter1[filter1[\"qid\"] == \"computes_average_of_list\"]\n",
    "print(filter2.shape)\n",
    "display_class_dist(filter2)\n",
    "\n",
    "display_class_dist(alldata_df[alldata_df[\"qid\"] == \"computes_average_of_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "disturbed-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   6.01% (184)\n",
      "(0, 0, 1)  13.38% (410)\n",
      "(0, 1, 0)   1.44% (44)\n",
      "(0, 1, 1)   9.76% (299)\n",
      "(1, 0, 0)   4.44% (136)\n",
      "(1, 1, 0)   6.59% (202)\n",
      "(1, 0, 1)  20.30% (622)\n",
      "(1, 1, 1)  38.09% (1167)\n"
     ]
    }
   ],
   "source": [
    "#distribution of all the data, even those tuples that were manually reconciled.\n",
    "display_class_dist(alldata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "vocational-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(studentresponse):    \n",
    "    words = word_tokenize(studentresponse)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    lower_words= [word.lower() for word in stemmed_words] #convert to lowercase\n",
    "    stemmed_words = lower_words\n",
    "    regular_alpha = [] \n",
    "    for word in stemmed_words:\n",
    "        if word.isalnum():  #remove any word that isn't an alphabet or a number.\n",
    "            regular_alpha.append(word)\n",
    "    stemmed_words = regular_alpha\n",
    "    \n",
    "    #TODO - need to handle stop words by passing in my own list. (related to tf-idf weighting)\n",
    "    \n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "annual-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance metrics\n",
    "#TODO: consider a few metrics\n",
    "\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    #compute the cosine similarity of two vectors\n",
    "\n",
    "    return sklearn.metrics.pairwise.cosine_similarity(x, y).item()     #using .item() to get value as a scalar\n",
    "    \n",
    "def distance_from_golden(golden, given_ans, dist_func):\n",
    "    #compute a distance metric for the distance between a given answer and the golden answer\n",
    "    distance = dist_func(golden, given_ans)\n",
    "    if distance == None:\n",
    "        return float(\"inf\")\n",
    "    else:\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "continuing-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, what_to_predict, accuracy):\n",
    "        '''\n",
    "        Function to help with plotting a confusion matrix\n",
    "        '''\n",
    "        plt.figure(figsize=(9,9))\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "        plt.ylabel('Actual label');\n",
    "        plt.xlabel('Predicted label');\n",
    "        all_sample_title = 'Accuracy Score for {thingtopredict}: {accscore:.2f}'.format(thingtopredict = what_to_predict,\n",
    "                                                                                    accscore = accuracy)\n",
    "        plt.title(all_sample_title, size = 15);\n",
    "        \n",
    "\n",
    "def process_raw_features(given_df, pct_for_train = 0.8):\n",
    "    \"\"\"\n",
    "    Process the raw text and get it ready to be trained\n",
    "    Return processed text as a list of lists, where each list is one student response or one row of data\n",
    "    \"\"\"\n",
    "    \n",
    "    numsamples = 0\n",
    "    limit = int(pct_for_train * len(given_df[\"response\"]))\n",
    "    processed_studentanswers = []\n",
    "    \n",
    "    for studentanswer in given_df[\"response\"]:\n",
    "        \n",
    "        processed_answer = preprocess_text(studentanswer)\n",
    "        processed_studentanswers.append(processed_answer)\n",
    "        numsamples += 1\n",
    "        \n",
    "        if numsamples == limit:\n",
    "            break\n",
    "    return processed_studentanswers\n",
    "\n",
    "\n",
    "def add_similarity_vector(golden_answers, students_responses_as_vec, curvec_fitter):\n",
    "    \"\"\"\n",
    "    Create a column vector that represents the distance of a given student answer from the golden answer\n",
    "    \"\"\"\n",
    "    golden_answers_vectors = curvec_fitter.transform(golden_answers).toarray()\n",
    "    \n",
    "    sim_vector = []\n",
    "    \n",
    "    #print(\"Shape of all student vectors = {}\".format(students_responses_as_vec.shape))\n",
    "    #print(\"Shape of golden_answers_vectors = {}\".format(golden_answers_vectors.shape))\n",
    "    \n",
    "    for curstudent_vec in students_responses_as_vec:\n",
    "        \n",
    "        #print(\"Shape single student vector = {}\".format(curstudent_vec.shape))\n",
    "        best_similar = float(\"-inf\") #ranges from 0 to 1 (1 meaning very similar or identical)\n",
    "        \n",
    "        for single_golden_answer_vec in golden_answers_vectors:\n",
    "            #print(\"Shape single golden answer vector = {}\".format(single_golden_answer_vec.shape))\n",
    "            #cur_distance = distance_from_golden(single_golden_answer_vec, curstudent_vec, cosine_similarity)\n",
    "            #compute distance. reshape the data into row vectors\n",
    "            \n",
    "            parta = single_golden_answer_vec.reshape(1,-1)\n",
    "            partb = curstudent_vec.reshape(1,-1)\n",
    "            \n",
    "            #print(\"After reshaping, current size = {} for golden answer and  {} for student vector\".format(parta.shape, partb.shape))\n",
    "            \n",
    "            cur_distance = cosine_similarity(parta, partb)\n",
    "            best_similar = max(best_similar, cur_distance)\n",
    "            \n",
    "        sim_vector.append(best_similar)\n",
    "    \n",
    "    sim_vector = np.array(sim_vector)\n",
    "    sim_vector = sim_vector.reshape(-1,1) #need to convert into a proper column vector\n",
    "    return sim_vector\n",
    "\n",
    "\n",
    "def train_model_and_validate(given_train_df, given_validate_df, golden_answers = [], qname = \"\"):\n",
    "    \n",
    "    ydims =  [\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "    \n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (1,2), min_df = 4)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    y_train = given_train_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    X_validate_processed_text = process_raw_features(given_validate_df, pct_for_train = 1)\n",
    "    X_validate = vec_fitter.transform(X_validate_processed_text).toarray()  #use the previously fitted vectorizer to maintain shape\n",
    "    y_validate = given_validate_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_validationset  = add_similarity_vector(golden_answers, X_validate, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_validate = np.append(X_validate, distance_from_golden_vector_validationset, axis = 1)\n",
    "        \n",
    "#         X_train.append(distance_from_golden_vector_trainset, axis = 1)\n",
    "#         X_validate.append(distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "        \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(3):\n",
    "        model = LogisticRegression(random_state = 0, solver = \"liblinear\")\n",
    "        \n",
    "        num_classes = list(np.unique(y_train[:,i])) #check number of classes in data. should be two\n",
    "        print(\"We have {} classes\".format(len(num_classes)))\n",
    "        if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "            y_train[-1, i] = 0 if y_train[-1, i] == 1 else 0\n",
    "        \n",
    "        model = model.fit(X_train, y_train[:,i]) #train only one column at a time\n",
    "        \n",
    "        binary_y_predictions = model.predict(X_validate)\n",
    "        \n",
    "        #use the withheld set for testing the model\n",
    "        print(\"{} Log reg. model performance on the withheld test set:\\n\\n\".format(labels_order[i]))\n",
    "        \n",
    "        #for the y_test data (the true labels for column i), check if the predictions match\n",
    "        dim_accuracy = metrics.accuracy_score(y_validate[:, i], binary_y_predictions)\n",
    "        print(\"Accuracy is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        #print(metrics.classification_report(y_test, binary_y_predictions))\n",
    "\n",
    "\n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_validate[:, i],binary_y_predictions, normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "       \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    return accuracy_l  #accuracy for the three dimensions for a given problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "quality-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID = 'print_found_if_three_numbers_unique.'\n",
      "Original X data shape = (96, 96), golden_answer_shape = (96, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5625\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.29411765 0.70588235]\n",
      " [0.13333333 0.86666667]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.78125\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.11538462 0.88461538]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.90625\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.4 0.6]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'print_items_out_smaller_then_larger.'\n",
      "Original X data shape = (291, 268), golden_answer_shape = (291, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7319587628865979\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.39285714 0.60714286]\n",
      " [0.13043478 0.86956522]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8144329896907216\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.53846154 0.46153846]\n",
      " [0.08450704 0.91549296]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9072164948453608\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.82142857 0.17857143]\n",
      " [0.05797101 0.94202899]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'computes_average_of_list.'\n",
      "Original X data shape = (72, 51), golden_answer_shape = (72, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9166666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "We have 1 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9583333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9583333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.9 0.1]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'does_list_have_value_above_y.'\n",
      "Original X data shape = (45, 56), golden_answer_shape = (45, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.55555556 0.44444444]\n",
      " [0.33333333 0.66666667]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6666666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.625      0.375     ]\n",
      " [0.28571429 0.71428571]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'count how many times a given string appears in a list regardless of case.'\n",
      "Original X data shape = (71, 76), golden_answer_shape = (71, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7916666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.16666667 0.83333333]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7083333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.94117647 0.05882353]\n",
      " [0.85714286 0.14285714]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9166666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.04761905 0.95238095]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'count how many numbers in a list are multiples of another number.'\n",
      "Original X data shape = (101, 79), golden_answer_shape = (101, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9117647058823529\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.625 0.375]\n",
      " [0.    1.   ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7647058823529411\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.38461538 0.61538462]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8823529411764706\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.75 0.25]\n",
      " [0.1  0.9 ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'a33_replace_all_ys_with_zs.'\n",
      "Original X data shape = (161, 152), golden_answer_shape = (161, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7777777777777778\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8        0.2       ]\n",
      " [0.24137931 0.75862069]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8888888888888888\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.80952381 0.19047619]\n",
      " [0.06060606 0.93939394]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8333333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.06666667 0.93333333]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'split a csv string and return the nth word.'\n",
      "Original X data shape = (91, 75), golden_answer_shape = (91, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8333333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.125      0.875     ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8666666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.94117647 0.05882353]\n",
      " [0.23076923 0.76923077]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'return the location of an element if it is in the list.'\n",
      "Original X data shape = (189, 129), golden_answer_shape = (189, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7301587301587301\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.42857143 0.57142857]\n",
      " [0.18367347 0.81632653]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8412698412698413\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.78378378 0.21621622]\n",
      " [0.07692308 0.92307692]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9841269841269841\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'list_copy_up_to_positive.'\n",
      "Original X data shape = (57, 76), golden_answer_shape = (57, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8421052631578947\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.07692308 0.92307692]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9473684210526315\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.9375 0.0625]\n",
      " [0.     1.    ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8947368421052632\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'find_largest_number_in_file.'\n",
      "Original X data shape = (208, 154), golden_answer_shape = (208, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8985507246376812\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5        0.5       ]\n",
      " [0.01754386 0.98245614]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.927536231884058\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.90322581 0.09677419]\n",
      " [0.05263158 0.94736842]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9420289855072463\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.     0.    ]\n",
      " [0.0625 0.9375]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'swaps_first_and_last.'\n",
      "Original X data shape = (137, 111), golden_answer_shape = (137, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8043478260869565\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.41666667 0.58333333]\n",
      " [0.05882353 0.94117647]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9130434782608695\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.96428571 0.03571429]\n",
      " [0.16666667 0.83333333]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6956521739130435\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.28571429 0.71428571]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'return whether strings start with the same letter.'\n",
      "Original X data shape = (85, 106), golden_answer_shape = (85, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8214285714285714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5        0.5       ]\n",
      " [0.09090909 0.90909091]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6428571428571429\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5625 0.4375]\n",
      " [0.25   0.75  ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9285714285714286\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5        0.5       ]\n",
      " [0.03846154 0.96153846]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'make_list_from_zero_to_x.'\n",
      "Original X data shape = (78, 87), golden_answer_shape = (78, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6153846153846154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.61538462 0.38461538]\n",
      " [0.38461538 0.61538462]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7692307692307693\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8125 0.1875]\n",
      " [0.3    0.7   ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5384615384615384\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.28571429 0.71428571]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'increase_all_numbers_by_y.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X data shape = (64, 61), golden_answer_shape = (64, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6363636363636364\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.44444444 0.55555556]\n",
      " [0.23076923 0.76923077]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8636363636363636\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.83333333 0.16666667]\n",
      " [0.1        0.9       ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9090909090909091\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.         0.        ]\n",
      " [0.13333333 0.86666667]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'absolute_value.'\n",
      "Original X data shape = (45, 34), golden_answer_shape = (45, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.625      0.375     ]\n",
      " [0.14285714 0.85714286]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6666666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.83333333 0.16666667]\n",
      " [0.44444444 0.55555556]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8666666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8 0.2]\n",
      " [0.1 0.9]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'is_even.'\n",
      "Original X data shape = (41, 35), golden_answer_shape = (41, 1)\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8571428571428571\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.09090909 0.90909091]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7857142857142857\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.4 0.6]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8571428571428571\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.         1.        ]\n",
      " [0.07692308 0.92307692]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2nd model which incorporates the distance to the closest golden answer \n",
    "\n",
    "import ast\n",
    "        \n",
    "\n",
    "qids_accuracy = []\n",
    "\n",
    "for cur_qid in alldata_df[\"qid\"].unique().tolist():\n",
    "    \n",
    "        \n",
    "    cur_question_training_df = train_df[train_df[\"qid\"] == cur_qid]\n",
    "    cur_question_validation_df = validate_df[validate_df[\"qid\"] == cur_qid]\n",
    "    \n",
    "    print(\"QID = \\'{}.\\'\".format(cur_qid))\n",
    "    qname_formatted = \": \" + cur_qid #format cur_qid name so it looks nice when printed with other function\n",
    "    \n",
    "    q_goldenanswers = cur_question_training_df[\"example_correct_answers\"].iloc[0]\n",
    "    q_goldenanswers = ast.literal_eval(q_goldenanswers)\n",
    "    \n",
    "    if type(q_goldenanswers) != list:\n",
    "        print(\"Had to convert to list\")\n",
    "        q_goldenanswers = [q_goldenanswers]\n",
    "\n",
    "    \n",
    "    cur_qid_accuracy = train_model_and_validate(cur_question_training_df, cur_question_validation_df, \n",
    "                                                qname = qname_formatted, golden_answers = q_goldenanswers)\n",
    "    \n",
    "    qids_accuracy.append(cur_qid_accuracy)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "supreme-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging results for all qids in each of the respective dimensions\n",
      "\n",
      "Avg accuracy for Unambig: 0.77\n",
      "Avg accuracy for Correct column: 0.81\n",
      "Avg accuracy for High-level column: 0.88\n",
      "\n",
      "\n",
      "Average results across all dimensions for all qids: 0.82\n",
      "Results done5\n"
     ]
    }
   ],
   "source": [
    "#show the accuracy of the classifier for each column across all data\n",
    "\n",
    "\n",
    "\n",
    "qids_accuracy = np.array(qids_accuracy)\n",
    "print(\"Averaging results for all qids in each of the respective dimensions\\n\")\n",
    "\n",
    "\n",
    "avg_unambig_accuracy = np.mean(qids_accuracy[:, 0])\n",
    "print(\"Avg accuracy for Unambig: {:.2f}\".format(avg_unambig_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "avg_corr_accuracy = np.mean(qids_accuracy[:, 1])\n",
    "print(\"Avg accuracy for Correct column: {:.2f}\".format(avg_corr_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "avg_highlvl_accuracy = np.mean(qids_accuracy[:, 2])\n",
    "print(\"Avg accuracy for High-level column: {:.2f}\\n\\n\".format(avg_highlvl_accuracy))\n",
    "\n",
    "\n",
    "avg_classifier_perf_overall = np.mean(qids_accuracy)\n",
    "print(\"Average results across all dimensions for all qids: {:.2f}\".format(avg_classifier_perf_overall))\n",
    "\n",
    "print(\"Results done5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
