{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adverse-gauge",
   "metadata": {},
   "source": [
    "Script serves two purposes:\n",
    "Curates data for 3d grader\n",
    "Builds models for grading EiPE answers (Data is 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "indoor-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\chine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "subjective-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"sigcse_2024.csv\"\n",
    "alldata_df = pd.read_csv(data_file, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "objective-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>embedding_subset</th>\n",
       "      <th>embedding_index</th>\n",
       "      <th>pl_qid</th>\n",
       "      <th>qid</th>\n",
       "      <th>code</th>\n",
       "      <th>assumption</th>\n",
       "      <th>example_correct_answers</th>\n",
       "      <th>response</th>\n",
       "      <th>binary_annotators</th>\n",
       "      <th>...</th>\n",
       "      <th>chinny_una</th>\n",
       "      <th>chinny_c</th>\n",
       "      <th>chinny_hl</th>\n",
       "      <th>binglin_una</th>\n",
       "      <th>binglin_c</th>\n",
       "      <th>binglin_hl</th>\n",
       "      <th>una</th>\n",
       "      <th>c</th>\n",
       "      <th>hl</th>\n",
       "      <th>3d_resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>97</td>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_1</td>\n",
       "      <td>print_found_if_three_numbers_unique</td>\n",
       "      <td>def f(x, y, z):\\n    if x != y and x != z and ...</td>\n",
       "      <td>Assume that the variables x, y, and z are inte...</td>\n",
       "      <td>['Print the word found if all three numbers ar...</td>\n",
       "      <td>the code checks if all arguments regarding var...</td>\n",
       "      <td>['Austin', 'Max']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate</td>\n",
       "      <td>train</td>\n",
       "      <td>113</td>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_1</td>\n",
       "      <td>print_items_out_smaller_then_larger</td>\n",
       "      <td>def f(x, y):\\n    if x &lt; y:\\n        print(x, ...</td>\n",
       "      <td>Assume that the variables x and y are integers.</td>\n",
       "      <td>['prints two given numbers in numberical order...</td>\n",
       "      <td>prints two numbers ordered smallest to largest</td>\n",
       "      <td>['Austin', 'Max']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>138</td>\n",
       "      <td>cdrd_exam1_manual/cdrd_exam1_2</td>\n",
       "      <td>computes_average_of_list</td>\n",
       "      <td>def f(x):\\n    return sum(x) / len(x)</td>\n",
       "      <td>Assume that the variable x is a non-empty list...</td>\n",
       "      <td>['Returns the average value in a list', 'finds...</td>\n",
       "      <td>returns the average of a list</td>\n",
       "      <td>['Binglin', 'Rachel']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validate</td>\n",
       "      <td>train</td>\n",
       "      <td>150</td>\n",
       "      <td>cdrd_week5_exam</td>\n",
       "      <td>does_list_have_value_above_y</td>\n",
       "      <td>def f(x, y):\\n    for val in x:\\n        if va...</td>\n",
       "      <td>Assume that the variable x is a list of intege...</td>\n",
       "      <td>['Return True if at least one list element is ...</td>\n",
       "      <td>returns whether the first value in a list is g...</td>\n",
       "      <td>['Binglin']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>228</td>\n",
       "      <td>cdrd_exam3_manual/cdrd_exam3_1</td>\n",
       "      <td>count how many times a given string appears in...</td>\n",
       "      <td>def f(x, y):\\n    k = 0\\n    for e in x:\\n    ...</td>\n",
       "      <td>Assume that variable x is a list of strings an...</td>\n",
       "      <td>['Return a count of how many times a given str...</td>\n",
       "      <td>return the number of times in which the string...</td>\n",
       "      <td>['Binglin', 'Rachel']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subset embedding_subset  embedding_index                          pl_qid  \\\n",
       "0     train            train               97  cdrd_exam1_manual/cdrd_exam1_1   \n",
       "1  validate            train              113  cdrd_exam1_manual/cdrd_exam1_1   \n",
       "2     train            train              138  cdrd_exam1_manual/cdrd_exam1_2   \n",
       "3  validate            train              150                 cdrd_week5_exam   \n",
       "4     train            train              228  cdrd_exam3_manual/cdrd_exam3_1   \n",
       "\n",
       "                                                 qid  \\\n",
       "0                print_found_if_three_numbers_unique   \n",
       "1                print_items_out_smaller_then_larger   \n",
       "2                           computes_average_of_list   \n",
       "3                       does_list_have_value_above_y   \n",
       "4  count how many times a given string appears in...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def f(x, y, z):\\n    if x != y and x != z and ...   \n",
       "1  def f(x, y):\\n    if x < y:\\n        print(x, ...   \n",
       "2              def f(x):\\n    return sum(x) / len(x)   \n",
       "3  def f(x, y):\\n    for val in x:\\n        if va...   \n",
       "4  def f(x, y):\\n    k = 0\\n    for e in x:\\n    ...   \n",
       "\n",
       "                                          assumption  \\\n",
       "0  Assume that the variables x, y, and z are inte...   \n",
       "1    Assume that the variables x and y are integers.   \n",
       "2  Assume that the variable x is a non-empty list...   \n",
       "3  Assume that the variable x is a list of intege...   \n",
       "4  Assume that variable x is a list of strings an...   \n",
       "\n",
       "                             example_correct_answers  \\\n",
       "0  ['Print the word found if all three numbers ar...   \n",
       "1  ['prints two given numbers in numberical order...   \n",
       "2  ['Returns the average value in a list', 'finds...   \n",
       "3  ['Return True if at least one list element is ...   \n",
       "4  ['Return a count of how many times a given str...   \n",
       "\n",
       "                                            response      binary_annotators  \\\n",
       "0  the code checks if all arguments regarding var...      ['Austin', 'Max']   \n",
       "1     prints two numbers ordered smallest to largest      ['Austin', 'Max']   \n",
       "2                      returns the average of a list  ['Binglin', 'Rachel']   \n",
       "3  returns whether the first value in a list is g...            ['Binglin']   \n",
       "4  return the number of times in which the string...  ['Binglin', 'Rachel']   \n",
       "\n",
       "   ...  chinny_una  chinny_c  chinny_hl  binglin_una  binglin_c  binglin_hl  \\\n",
       "0  ...           0         0        0.0            0          0           0   \n",
       "1  ...           1         1        1.0            1          1           1   \n",
       "2  ...           1         1        1.0            1          1           1   \n",
       "3  ...           1         0        1.0            1          0           1   \n",
       "4  ...           1         1        0.0            1          1           1   \n",
       "\n",
       "   una  c  hl  3d_resolution  \n",
       "0    1  0   0      reconcile  \n",
       "1    0  1   1      reconcile  \n",
       "2    1  1   1      reconcile  \n",
       "3    1  0   1      reconcile  \n",
       "4    1  1   1      reconcile  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "south-presentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 24)\n"
     ]
    }
   ],
   "source": [
    "print(alldata_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "laden-botswana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_class_dist(given_df):\n",
    "    '''\n",
    "    Display the distribution of data for each qid. There are 8 possible bins.\n",
    "    '''\n",
    "    classes =  {(0,0,0): 0, (0,0,1):0, (0,1,0):0, (0,1,1):0, \n",
    "                (1,0,0):0, (1,1,0):0, (1,0,1):0, (1,1,1):0}\n",
    "    \n",
    "    ordering = [(0,0,0), (0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,1,0), (1,0,1), (1,1,1)]\n",
    "    \n",
    "    print(\"3D groupings = (unambig, correct, highlevel)\\n\\n\")\n",
    "    print(\"3D label,  Freq. (Num Times Occur)\")\n",
    "    \n",
    "    numrowsdata = 0\n",
    "    \n",
    "    for index, row in given_df.iterrows():\n",
    "        \n",
    "        cur_unambig = row[\"una\"]\n",
    "        cur_correct = row[\"c\"]\n",
    "        cur_hl      = row[\"hl\"]\n",
    "        \n",
    "        classes[(cur_unambig, cur_correct, cur_hl)] += 1\n",
    "        numrowsdata += 1\n",
    "    \n",
    "    for curbin in ordering:\n",
    "        curbincount = classes[curbin] #get the number of occurrences of a particular labeling configuration within the data\n",
    "        print(\"{}  {:>5.2f}% ({})\".format(curbin, round(100*curbincount/numrowsdata, 2), curbincount)) #print group name, group freq and raw count of group occur.\n",
    "\n",
    "\n",
    "    \n",
    "def qid_dist(given_df):\n",
    "    \"\"\"\n",
    "    Show how frequently each qid occured in the data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "handed-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1832, 24)\n",
      "(72, 24)\n",
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   0.00% (0)\n",
      "(0, 0, 1)   0.00% (0)\n",
      "(0, 1, 0)   0.00% (0)\n",
      "(0, 1, 1)   8.33% (6)\n",
      "(1, 0, 0)   0.00% (0)\n",
      "(1, 1, 0)  44.44% (32)\n",
      "(1, 0, 1)   0.00% (0)\n",
      "(1, 1, 1)  47.22% (34)\n",
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   0.00% (0)\n",
      "(0, 0, 1)   0.00% (0)\n",
      "(0, 1, 0)   0.00% (0)\n",
      "(0, 1, 1)   9.17% (11)\n",
      "(1, 0, 0)   0.83% (1)\n",
      "(1, 1, 0)  42.50% (51)\n",
      "(1, 0, 1)   0.00% (0)\n",
      "(1, 1, 1)  47.50% (57)\n"
     ]
    }
   ],
   "source": [
    "filter1 = alldata_df[alldata_df[\"subset\"] == \"train\"]\n",
    "print(filter1.shape)\n",
    "filter2= filter1[filter1[\"qid\"] == \"computes_average_of_list\"]\n",
    "print(filter2.shape)\n",
    "display_class_dist(filter2)\n",
    "\n",
    "display_class_dist(alldata_df[alldata_df[\"qid\"] == \"computes_average_of_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "disturbed-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D groupings = (unambig, correct, highlevel)\n",
      "\n",
      "\n",
      "3D label,  Freq. (Num Times Occur)\n",
      "(0, 0, 0)   6.01% (184)\n",
      "(0, 0, 1)  13.38% (410)\n",
      "(0, 1, 0)   1.44% (44)\n",
      "(0, 1, 1)   9.76% (299)\n",
      "(1, 0, 0)   4.44% (136)\n",
      "(1, 1, 0)   6.59% (202)\n",
      "(1, 0, 1)  20.30% (622)\n",
      "(1, 1, 1)  38.09% (1167)\n"
     ]
    }
   ],
   "source": [
    "#distribution of all the data, even those tuples that were manually reconciled.\n",
    "display_class_dist(alldata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "vocational-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(studentresponse):    \n",
    "    words = word_tokenize(studentresponse)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    lower_words= [word.lower() for word in stemmed_words] #convert to lowercase\n",
    "    stemmed_words = lower_words\n",
    "    regular_alpha = [] \n",
    "    for word in stemmed_words:\n",
    "        if word.isalnum():  #remove any word that isn't an alphabet or a number.\n",
    "            regular_alpha.append(word)\n",
    "    stemmed_words = regular_alpha\n",
    "    \n",
    "    #TODO - need to handle stop words by passing in my own list. (related to tf-idf weighting)\n",
    "    \n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "annual-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance metrics\n",
    "#TODO: consider a few metrics\n",
    "\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    #compute the cosine similarity of two vectors\n",
    "\n",
    "    return sklearn.metrics.pairwise.cosine_similarity(x, y).item()     #using .item() to get value as a scalar\n",
    "    \n",
    "def distance_from_golden(golden, given_ans, dist_func):\n",
    "    #compute a distance metric for the distance between a given answer and the golden answer\n",
    "    distance = dist_func(golden, given_ans)\n",
    "    if distance == None:\n",
    "        return float(\"inf\")\n",
    "    else:\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "immune-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the groupings (e.g 0-1-1 will be marked as 1 for ambiguous, any other combo is 0 for ambiguous)\n",
    "def make_binary_col_if_group_found(givendf1, givendims, newcolname):\n",
    "    \n",
    "    tuple_found = []\n",
    "    \n",
    "    for index, row in givendf1.iterrows():\n",
    "        \n",
    "        cur_unambig = row[\"una\"]\n",
    "        cur_correct = row[\"c\"]\n",
    "        cur_hl      = row[\"hl\"]\n",
    "        \n",
    "        cur_pair = (cur_unambig, cur_correct, cur_hl)\n",
    "        if cur_pair == givendims:\n",
    "            tuple_found.append(1)\n",
    "        else:\n",
    "            tuple_found.append(0)\n",
    "    \n",
    "    newdf = givendf1.copy()\n",
    "    res = pd.Series(tuple_found)\n",
    "    newdf[newcolname] = res\n",
    "    \n",
    "    #givendf[newcolname] = pd.Series(tuple_found)\n",
    "    \n",
    "    print(\"unique values in tuple = \", set(tuple_found))\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "continuing-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, what_to_predict, accuracy ):\n",
    "        '''\n",
    "        Function to help with plotting a confusion matrix\n",
    "        '''\n",
    "        plt.figure(figsize=(9,9))\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "        plt.ylabel('Actual label');\n",
    "        plt.xlabel('Predicted label');\n",
    "        all_sample_title = 'Accuracy Score for {thingtopredict}: {accscore:.2f}'.format(thingtopredict = what_to_predict,\n",
    "                                                                                    accscore = accuracy)\n",
    "        plt.title(all_sample_title, size = 15);\n",
    "        \n",
    "\n",
    "def process_raw_features(given_df, pct_for_train = 0.8):\n",
    "    \"\"\"\n",
    "    Process the raw text and get it ready to be trained\n",
    "    Return processed text as a list of lists, where each list is one student response or one row of data\n",
    "    \"\"\"\n",
    "    \n",
    "    numsamples = 0\n",
    "    limit = int(pct_for_train * len(given_df[\"response\"]))\n",
    "    processed_studentanswers = []\n",
    "    \n",
    "    for studentanswer in given_df[\"response\"]:\n",
    "        \n",
    "        processed_answer = preprocess_text(studentanswer)\n",
    "        processed_studentanswers.append(processed_answer)\n",
    "        numsamples += 1\n",
    "        \n",
    "        if numsamples == limit:\n",
    "            break\n",
    "    return processed_studentanswers\n",
    "\n",
    "\n",
    "def add_similarity_vector(golden_answers, students_responses_as_vec, curvec_fitter):\n",
    "    \"\"\"\n",
    "    Create a column vector that represents the distance of a given student answer from the golden answer\n",
    "    \"\"\"\n",
    "    golden_answers_vectors = curvec_fitter.transform(golden_answers).toarray()\n",
    "    \n",
    "    sim_vector = []\n",
    "    \n",
    "    #print(\"Shape of all student vectors = {}\".format(students_responses_as_vec.shape))\n",
    "    #print(\"Shape of golden_answers_vectors = {}\".format(golden_answers_vectors.shape))\n",
    "    \n",
    "    for curstudent_vec in students_responses_as_vec:\n",
    "        \n",
    "        #print(\"Shape single student vector = {}\".format(curstudent_vec.shape))\n",
    "        best_similar = float(\"-inf\") #ranges from 0 to 1 (1 meaning very similar or identical)\n",
    "        \n",
    "        for single_golden_answer_vec in golden_answers_vectors:\n",
    "            #print(\"Shape single golden answer vector = {}\".format(single_golden_answer_vec.shape))\n",
    "            #cur_distance = distance_from_golden(single_golden_answer_vec, curstudent_vec, cosine_similarity)\n",
    "            #compute distance. reshape the data into row vectors\n",
    "            \n",
    "            parta = single_golden_answer_vec.reshape(1,-1)\n",
    "            partb = curstudent_vec.reshape(1,-1)\n",
    "            \n",
    "            #print(\"After reshaping, current size = {} for golden answer and  {} for student vector\".format(parta.shape, partb.shape))\n",
    "            \n",
    "            cur_distance = cosine_similarity(parta, partb)\n",
    "            best_similar = max(best_similar, cur_distance)\n",
    "            \n",
    "        sim_vector.append(best_similar)\n",
    "    \n",
    "    sim_vector = np.array(sim_vector)\n",
    "    sim_vector = sim_vector.reshape(-1,1) #need to convert into a proper column vector\n",
    "    return sim_vector\n",
    "\n",
    "\n",
    "def train_model_and_validate(given_train_df, given_validate_df, golden_answers = [], qname = \"\"):\n",
    "    \n",
    "    ydims =  [\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "    \n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (1,2), min_df = 30)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    y_train = given_train_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    X_validate_processed_text = process_raw_features(given_validate_df, pct_for_train = 1)\n",
    "    X_validate = vec_fitter.transform(X_validate_processed_text).toarray()  #use the previously fitted vectorizer to maintain shape\n",
    "    y_validate = given_validate_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_validationset  = add_similarity_vector(golden_answers, X_validate, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_validate = np.append(X_validate, distance_from_golden_vector_validationset, axis = 1)\n",
    "        \n",
    "#         X_train.append(distance_from_golden_vector_trainset, axis = 1)\n",
    "#         X_validate.append(distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "        \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(3):\n",
    "        model = LogisticRegression(random_state = 0)\n",
    "        \n",
    "        num_classes = list(np.unique(y_train[:,i])) #check number of classes in data. should be two\n",
    "        print(\"We have {} classes\".format(len(num_classes)))\n",
    "        if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "            y_train[-1, i] = 0 if y_train[-1, i] == 1 else 0\n",
    "        \n",
    "        model = model.fit(X_train, y_train[:,i]) #train only one column at a time\n",
    "        \n",
    "        binary_y_predictions = model.predict(X_validate)\n",
    "        \n",
    "        #use the withheld set for testing the model\n",
    "        print(\"{} Log reg. model performance on the withheld test set:\\n\\n\".format(labels_order[i]))\n",
    "        \n",
    "        #for the y_test data (the true labels for column i), check if the predictions match\n",
    "        dim_accuracy = metrics.accuracy_score(y_validate[:, i], binary_y_predictions)\n",
    "        print(\"Accuracy is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        #print(metrics.classification_report(y_test, binary_y_predictions))\n",
    "\n",
    "\n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_validate[:, i],binary_y_predictions, normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "       \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    return accuracy_l  #accuracy for the three dimensions for a given problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "informed-seafood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in tuple =  {0, 1}\n",
      "unique values in tuple =  {0, 1}\n",
      "unique values in tuple =  {0, 1}\n",
      "QID = 'print_found_if_three_numbers_unique.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.17647059 0.82352941]\n",
      " [0.13333333 0.86666667]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8125\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5        0.5       ]\n",
      " [0.11538462 0.88461538]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9375\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.6 0.4]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'print_items_out_smaller_then_larger.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6907216494845361\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.25       0.75      ]\n",
      " [0.13043478 0.86956522]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8041237113402062\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5        0.5       ]\n",
      " [0.08450704 0.91549296]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8762886597938144\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.75       0.25      ]\n",
      " [0.07246377 0.92753623]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'computes_average_of_list.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9166666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "We have 1 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9583333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9583333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.9 0.1]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'does_list_have_value_above_y.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.44444444 0.55555556]\n",
      " [0.16666667 0.83333333]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.875 0.125]\n",
      " [0.    1.   ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'count how many times a given string appears in a list regardless of case.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7916666666666666\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.05555556 0.94444444]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7083333333333334\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.94117647 0.05882353]\n",
      " [0.85714286 0.14285714]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.875\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.33333333 0.66666667]\n",
      " [0.04761905 0.95238095]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'count how many numbers in a list are multiples of another number.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8823529411764706\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5 0.5]\n",
      " [0.  1. ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7647058823529411\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.38461538 0.61538462]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9117647058823529\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.75       0.25      ]\n",
      " [0.06666667 0.93333333]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'a33_replace_all_ys_with_zs.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7222222222222222\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8        0.2       ]\n",
      " [0.34482759 0.65517241]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8518518518518519\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.76190476 0.23809524]\n",
      " [0.09090909 0.90909091]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8703703703703703\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.55555556 0.44444444]\n",
      " [0.06666667 0.93333333]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'split a csv string and return the nth word.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7666666666666667\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.66666667 0.33333333]\n",
      " [0.20833333 0.79166667]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.88235294 0.11764706]\n",
      " [0.46153846 0.53846154]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9333333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'return the location of an element if it is in the list.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7301587301587301\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.21428571 0.78571429]\n",
      " [0.12244898 0.87755102]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8412698412698413\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.81081081 0.18918919]\n",
      " [0.11538462 0.88461538]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9841269841269841\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'list_copy_up_to_positive.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.631578947368421\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.16666667 0.83333333]\n",
      " [0.15384615 0.84615385]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7894736842105263\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8125     0.1875    ]\n",
      " [0.33333333 0.66666667]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8421052631578947\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'find_largest_number_in_file.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8840579710144928\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.5        0.5       ]\n",
      " [0.03508772 0.96491228]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.7971014492753623\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.87096774 0.12903226]\n",
      " [0.26315789 0.73684211]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9710144927536232\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.      0.     ]\n",
      " [0.03125 0.96875]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'swaps_first_and_last.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6956521739130435\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.25       0.75      ]\n",
      " [0.14705882 0.85294118]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6956521739130435\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.75       0.25      ]\n",
      " [0.38888889 0.61111111]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6739130434782609\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.44444444 0.55555556]\n",
      " [0.17857143 0.82142857]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'return whether strings start with the same letter.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.         1.        ]\n",
      " [0.04545455 0.95454545]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.75\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.625      0.375     ]\n",
      " [0.08333333 0.91666667]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.9285714285714286\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'make_list_from_zero_to_x.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5769230769230769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.84615385 0.15384615]\n",
      " [0.69230769 0.30769231]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6923076923076923\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.8125 0.1875]\n",
      " [0.5    0.5   ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.5\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.25       0.75      ]\n",
      " [0.28571429 0.71428571]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'increase_all_numbers_by_y.'\n",
      "We have 2 classes\n",
      "Unambig Log reg. model performance on the withheld test set:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy is =  0.6818181818181818\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.22222222 0.77777778]\n",
      " [0.         1.        ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "Correct Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.8636363636363636\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.91666667 0.08333333]\n",
      " [0.2        0.8       ]]\n",
      "\n",
      "\n",
      "\n",
      "We have 2 classes\n",
      "High level Log reg. model performance on the withheld test set:\n",
      "\n",
      "\n",
      "Accuracy is =  0.6818181818181818\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.57142857 0.42857143]\n",
      " [0.26666667 0.73333333]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QID = 'absolute_value.'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-10eced05b995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mqname_formatted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcur_qid\u001b[0m \u001b[1;31m#format cur_qid name so it looks nice when printed with other function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mcur_qid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model_and_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_question_training_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_question_validation_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqname_formatted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mqids_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_qid_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-142-db10643ddb13>\u001b[0m in \u001b[0;36mtrain_model_and_validate\u001b[1;34m(given_train_df, given_validate_df, golden_answers, qname)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mvec_fitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_processed_text\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#fit only on training data to prevent overfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chine\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \"\"\"\n\u001b[0;32m   1169\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chine\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0m\u001b[0;32m   1223\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chine\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[1;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[0;32m   1094\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[0;32m   1095\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "#for each question, create the input representation\n",
    "#train various models, bigrams, bigrams + distance_from_golden, report on performance\n",
    "\n",
    "train_pct = 1 #num from 0 to 1. currently 1 because want to train with 100% of train dataset\n",
    "qids_accuracy = []\n",
    "\n",
    "col_wrong = [\"not unambig\", \"not c\", \"not hl\"]\n",
    "col_for_feedback = [(0,1,1), (1,0,1), (1,1,0)]\n",
    "\n",
    "#col_for_feedback = {\"not hl\": (1,1,0), \"not c\": (1,0,1), \"not unambig\": (0,1,1)}\n",
    "\n",
    "#make sure that we have the one vs all for all data before splitting\n",
    "for i in range(3):\n",
    "    #alldata_df = make_binary_col_if_group_found(alldata_df,  col_for_feedback[col_wrong], col_wrong)\n",
    "    alldata_df = make_binary_col_if_group_found(alldata_df,  col_for_feedback[i], col_wrong[i])\n",
    "    \n",
    "    \n",
    "train_df    = alldata_df[alldata_df[\"subset\"] == \"train\"]       #select only training rows\n",
    "validate_df = alldata_df[alldata_df[\"subset\"] == \"validate\"] #only validation row\n",
    "test_df     = alldata_df[alldata_df[\"subset\"] == \"test\"]\n",
    "\n",
    "\n",
    "#alldata_df[alldata_df[\"subset\"] == \"train\" & alldata_df[\"qid\"] == \"computes average of list\"]\n",
    "\n",
    "\n",
    "for cur_qid in alldata_df[\"qid\"].unique().tolist():\n",
    "    \n",
    "    cur_question_training_df = train_df[train_df[\"qid\"] == cur_qid]\n",
    "    cur_question_validation_df = validate_df[validate_df[\"qid\"] == cur_qid]\n",
    "    cur_question_test_df = test_df[test_df[\"qid\"] == cur_qid]\n",
    "    \n",
    "    print(\"QID = \\'{}.\\'\".format(cur_qid))\n",
    "    qname_formatted = \": \" + cur_qid #format cur_qid name so it looks nice when printed with other function\n",
    "    \n",
    "    cur_qid_accuracy = train_model_and_validate(cur_question_training_df, cur_question_validation_df, qname = qname_formatted)\n",
    "    \n",
    "    qids_accuracy.append(cur_qid_accuracy)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd model which incorporates the distance to the closest golden answer \n",
    "\n",
    "import ast\n",
    "        \n",
    "\n",
    "for cur_qid in alldata_df[\"qid\"].unique().tolist():\n",
    "    \n",
    "        \n",
    "    cur_question_training_df = train_df[train_df[\"qid\"] == cur_qid]\n",
    "    cur_question_validation_df = validate_df[validate_df[\"qid\"] == cur_qid]\n",
    "    cur_question_test_df = test_df[test_df[\"qid\"] == cur_qid]\n",
    "    \n",
    "    print(\"QID = \\'{}.\\'\".format(cur_qid))\n",
    "    qname_formatted = \": \" + cur_qid #format cur_qid name so it looks nice when printed with other function\n",
    "    \n",
    "    q_goldenanswers = cur_question_training_df[\"example_correct_answers\"].iloc[0]\n",
    "    q_goldenanswers = ast.literal_eval(q_goldenanswers)\n",
    "    \n",
    "    if type(q_goldenanswers) != list:\n",
    "        print(\"Had to convert to list\")\n",
    "        q_goldenanswers = [q_goldenanswers]\n",
    "\n",
    "    \n",
    "    cur_qid_accuracy = train_model_and_validate(cur_question_training_df, cur_question_test_df, \n",
    "                                                qname = qname_formatted, golden_answers = q_goldenanswers)\n",
    "    \n",
    "    qids_accuracy.append(cur_qid_accuracy)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the accuracy of the classifier for each column across all data\n",
    "\n",
    "\n",
    "\n",
    "qids_accuracy = np.array(qids_accuracy)\n",
    "print(\"Averaging results for all qids in each of the respective dimensions\\n\")\n",
    "\n",
    "\n",
    "avg_unambig_accuracy = np.mean(qids_accuracy[:, 0])\n",
    "print(\"Avg accuracy for Unambig: {:.2f}\".format(avg_unambig_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "avg_corr_accuracy = np.mean(qids_accuracy[:, 1])\n",
    "print(\"Avg accuracy for Correct column: {:.2f}\".format(avg_corr_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "avg_highlvl_accuracy = np.mean(qids_accuracy[:, 2])\n",
    "print(\"Avg accuracy for High-level column: {:.2f}\\n\\n\".format(avg_highlvl_accuracy))\n",
    "\n",
    "\n",
    "avg_classifier_perf_overall = np.mean(qids_accuracy)\n",
    "print(\"Average results across all dimensions for all qids: {:.2f}\".format(avg_classifier_perf_overall))\n",
    "\n",
    "print(\"Results done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_validate_one_versus_all(given_train_df, given_validate_df, one_vs_all_col, golden_answers = [], qname = \"\"):\n",
    "    \n",
    "    ydims =  [\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "    \n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2), min_df = 2)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    y_train = given_train_df[one_vs_all_col].to_numpy(dtype=int) #training on special column\n",
    "    print(\"Raw Ys = \\n\\n\", given_train_df[one_vs_all_col].to_string())\n",
    "    print(\"------------------------\")\n",
    "    X_validate_processed_text = process_raw_features(given_validate_df, pct_for_train = 1)\n",
    "    X_validate = vec_fitter.transform(X_validate_processed_text).toarray()  #use the previously fitted vectorizer to maintain shape\n",
    "    y_validate = given_validate_df[one_vs_all_col].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    print(\"validating on {} col\".format(one_vs_all_col))\n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_validationset  = add_similarity_vector(golden_answers, X_validate, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_validate = np.append(X_validate, distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    #ensure that we have at least one tuple matching the condition by perturbing the input. \n",
    "    num_classes = list(np.unique(y_train)) #check number of classes in data. should be two\n",
    "    print(\"We have {} classes\".format(len(num_classes)))\n",
    "    print(\"Classes are = \", np.unique(y_train))\n",
    "    if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "            \n",
    "            #y_train[-1] = 0 if y_train[-1] == 1 else 0\n",
    "            if y_train[-1] == 1:\n",
    "                \n",
    "                y_train[-1] = 0\n",
    "            \n",
    "            elif y_train[-1] == 0:\n",
    "                \n",
    "                y_train[-1] = 1\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"Invalid Entry\")\n",
    "                \n",
    "            print(\"We now have {} classes in y train\".format(len(np.unique(y_train))))\n",
    "            \n",
    "    model = LogisticRegression(random_state = 0)\n",
    "    model = model.fit(X_train, y_train) #train only one column, in this case one of the one-vs-all classifiers\n",
    "        \n",
    "    binary_y_predictions = model.predict(X_validate) #validate on the original data\n",
    "        \n",
    "        \n",
    "        #for the y_test data (the true labels for column i), check if the predictions match\n",
    "    dim_accuracy = metrics.accuracy_score(y_validate, binary_y_predictions)\n",
    "    print(\"Accuracy for {} is = {} \".format(one_vs_all_col, dim_accuracy))\n",
    "    #print(metrics.classification_report(y_test, binary_y_predictions))\n",
    "\n",
    "\n",
    "    print(\"\\n\\nConfusion Matrix:\")    \n",
    "    confusion_matrix = metrics.confusion_matrix(y_validate, binary_y_predictions, normalize=\"true\")\n",
    "    print(confusion_matrix)\n",
    "        \n",
    "       \n",
    "    #uncomment next line to print the confusion matrix\n",
    "    #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "    print(\"\\n\\n\")\n",
    "        \n",
    "    return dim_accuracy  #accuracy for the three dimensions for a given problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models for training 1-1-0, 1-0-1, 0-1-1\n",
    "\n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "one_v_all = []\n",
    "\n",
    "for cur_qid in alldata_df[\"qid\"].unique().tolist():\n",
    "    \n",
    "        \n",
    "    cur_question_training_df = train_df[train_df[\"qid\"] == cur_qid].copy()\n",
    "    cur_question_validation_df = validate_df[validate_df[\"qid\"] == cur_qid].copy()\n",
    "    cur_question_test_df = test_df[test_df[\"qid\"] == cur_qid].copy()\n",
    "    \n",
    "    one_v_all_current = [] #store the accuracy numbers for a one-vs-all classifier\n",
    "    \n",
    "    print(\"QID = \\'{}.\\'\".format(cur_qid))\n",
    "    qname_formatted = \": \" + cur_qid #format cur_qid name so it looks nice when printed with other function\n",
    "    \n",
    "    q_goldenanswers = cur_question_training_df[\"example_correct_answers\"].iloc[0]\n",
    "    q_goldenanswers = ast.literal_eval(q_goldenanswers)\n",
    "    \n",
    "    if type(q_goldenanswers) != list:\n",
    "        print(\"Had to convert to list\")\n",
    "        q_goldenanswers = [q_goldenanswers]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(3):\n",
    "       # cur_question_training_df = make_binarycol_if_group_found(cur_question_training_df, col_for_feedback[col_wrong],  col_wrong)\n",
    "       #cur_question_validation_df = make_binarycol_if_group_found(cur_question_validation_df, col_for_feedback[col_wrong], col_wrong)\n",
    "        print(\"Right before training, Y = \", list(cur_question_training_df[col_wrong[i]]))\n",
    "        cur_qid_accuracy_dim = train_model_and_validate_one_versus_all(cur_question_training_df, cur_question_test_df, \n",
    "                                                                       col_wrong[i],\n",
    "                                                qname = qname_formatted, golden_answers = q_goldenanswers)\n",
    "        \n",
    "        one_v_all_current.append(cur_qid_accuracy_dim)\n",
    "        \n",
    "        \n",
    "    one_v_all.append(one_v_all_current)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_v_all - list of 3d lists\n",
    "print(\"Hi there\")\n",
    "\n",
    "one_v_all_accuracy = np.array(one_v_all)\n",
    "print(\"Averaging results for all qids in each of the respective dimensions\\n\")\n",
    "\n",
    "avg_unambig_accuracy_one_v_all = np.mean(one_v_all_accuracy[:, 0])\n",
    "print(\"Avg accuracy for Unambig: {:.2f}\".format(avg_unambig_accuracy))\n",
    "\n",
    "\n",
    "avg_corr_accuracy_one_v_all_accuracy = np.mean(one_v_all_accuracy[:, 1])\n",
    "print(\"Avg accuracy for Correct column: {:.2f}\".format(avg_corr_accuracy_one_v_all_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "avg_highlvl_accuracy_one_v_all_accuracy = np.mean(one_v_all_accuracy[:, 2])\n",
    "print(\"Avg accuracy for High-level column: {:.2f}\\n\\n\".format(avg_highlvl_accuracy_one_v_all_accuracy))\n",
    "\n",
    "\n",
    "avg_classifier_perf_overall_one_v_all_accuracy = np.mean(one_v_all_accuracy)\n",
    "print(\"Average results across all dimensions for all qids: {:.2f}\".format(avg_classifier_perf_overall_one_v_all_accuracy))\n",
    "\n",
    "print(\"Hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_and_validate_specify_order(given_train_df, given_validate_df, golden_answers = [], given_dims_order = [], qname = \"\"):\n",
    "    \n",
    "    ydims = given_dims_order #[\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "\n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2), min_df = 2)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_train = given_train_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    X_validate_processed_text = process_raw_features(given_validate_df, pct_for_train = 1)\n",
    "    X_validate = vec_fitter.transform(X_validate_processed_text).toarray()  #use the previously fitted vectorizer to maintain shape\n",
    "    y_validate = given_validate_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_validationset  = add_similarity_vector(golden_answers, X_validate, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_validate = np.append(X_validate, distance_from_golden_vector_validationset, axis = 1)\n",
    "        \n",
    "#         X_train.append(distance_from_golden_vector_trainset, axis = 1)\n",
    "#         X_validate.append(distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "  \n",
    "    \n",
    "    col1name, col2name, col3name = given_dims_order #order of the y dimensions\n",
    "    \n",
    "    y_firstcol_train_vector = given_train_df[col1name].to_numpy(dtype=int) \n",
    "    y_secondcol_train_vector = given_train_df[col2name].to_numpy(dtype=int)\n",
    "    y_thirdcol_train_vector = given_train_df[col3name].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    #potential\n",
    "    \n",
    "    firstdim_feedback_indices = []\n",
    "    seconddim_feedback_indices = []\n",
    "    thirddim_feedback_indices = []\n",
    "    \n",
    "    \n",
    "    num_classes = list(np.unique(y_firstcol_train_vector)) #check number of classes in data. should be two\n",
    "    if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        y_firstcol_train_vector[-1] = 0 if y_firstcol_train_vector[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model1 = LogisticRegression(random_state = 0)\n",
    "    model1 = model1.fit(X_train, y_firstcol_train_vector) #train only one column at a time\n",
    "    round1_y_predictions = model1.predict(X_train)\n",
    "    \n",
    "    \n",
    "    for i in range(len(round1_y_predictions)):\n",
    "        if round1_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially for next dimension\n",
    "            firstdim_feedback_indices.append(i)\n",
    "\n",
    "    round2_X_train_input = []\n",
    "    round2_y_train_input = []\n",
    "    for cur_index in firstdim_feedback_indices:\n",
    "        round2_X_train_input.append(X_train[cur_index, :])\n",
    "        round2_y_train_input.append(y_secondcol_train_vector[cur_index])\n",
    "    \n",
    "    \n",
    "    round2_X_train_input = np.array(round2_X_train_input)\n",
    "    round2_y_train_input = np.array(round2_y_train_input)\n",
    "    \n",
    "        \n",
    "    \n",
    "    num_classes2 = list(np.unique(round2_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes2) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round2_y_train_input[-1] = 0 if round2_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    model2 = LogisticRegression(random_state = 0)\n",
    "    model2 = model2.fit(round2_X_train_input, round2_y_train_input)\n",
    "    round2_y_predictions = model2.predict(round2_X_train_input)\n",
    "    \n",
    "    \n",
    "    round3_X_train_input = []\n",
    "    round3_y_train_input = []\n",
    "    for i  in range(len(round2_y_predictions)):\n",
    "        \n",
    "        if round2_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially needed for next dinmension\n",
    "            \n",
    "            round3_X_train_input.append(round2_X_train_input[i])\n",
    "            round3_y_train_input.append(y_thirdcol_train_vector[i])\n",
    "    \n",
    "        \n",
    "    num_classes3 = list(np.unique(round3_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes3) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round3_y_train_input[-1] = 0 if round3_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model3 = LogisticRegression(random_state = 0)\n",
    "    model3 = model3.fit(round3_X_train_input, round3_y_train_input)\n",
    "    round3_y_predictions = model3.predict(round3_X_train_input)\n",
    "    \n",
    "    classification_predictions = []\n",
    "    \n",
    "    print(\"input validation =\", type(X_validate), \" shape\", X_validate.shape)\n",
    "    classification_predictions = model1.predict(X_validate).reshape(-1,1)\n",
    "    #print(\"model 1 predictions type = \", type(cola))\n",
    "    classification_predictions = np.append(classification_predictions, model2.predict(X_validate).reshape(-1,1), axis = 1)\n",
    "    classification_predictions = np.append(classification_predictions, model3.predict(X_validate).reshape(-1,1), axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for given_response_vec in X_validate:\n",
    "#         print(\"asking for prediction for = \", type(given_response_vec))\n",
    "#         classifed = model1.predict(given_response_vec) + model2.predict(given_response_vec) + model3.predict(given_response_vec)\n",
    "#         print(\"prediction should be list = \", type(classified))\n",
    "#         classification_predictions.append(classified)\n",
    "    \n",
    "   #classification_predictions = np.array(classification_predictions)\n",
    "    \n",
    "    accuracy_l = []\n",
    "    for i in range(3):\n",
    "        dim_accuracy = metrics.accuracy_score(y_validate[:, i], classification_predictions[:,i])\n",
    "        print(\"Accuracy is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        \n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_validate[:, i], classification_predictions[:,i], normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    return accuracy_l  #accuracy for the three dimensions for a given problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_and_validate_specify_order(given_train_df, given_test_df, golden_answers = [], given_dims_order = [], qname = \"\"):\n",
    "    \n",
    "    ydims = given_dims_order #[\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "\n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2), min_df = 2)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    y_train = given_train_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    X_test_processed_text = process_raw_features(given_test_df, pct_for_train = 1)\n",
    "    X_test = vec_fitter.transform(X_test_processed_text).toarray()\n",
    "    y_test = given_test_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_testset  = add_similarity_vector(golden_answers, X_test, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_test = np.append(X_test, distance_from_golden_vector_testset, axis = 1)\n",
    "        \n",
    "#         X_train.append(distance_from_golden_vector_trainset, axis = 1)\n",
    "#         X_validate.append(distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "  \n",
    "    \n",
    "    col1name, col2name, col3name = given_dims_order #order of the y dimensions\n",
    "    \n",
    "    y_firstcol_train_vector = given_train_df[col1name].to_numpy(dtype=int) \n",
    "    y_secondcol_train_vector = given_train_df[col2name].to_numpy(dtype=int)\n",
    "    y_thirdcol_train_vector = given_train_df[col3name].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    #potential\n",
    "    \n",
    "    firstdim_feedback_indices = []\n",
    "    seconddim_feedback_indices = []\n",
    "    thirddim_feedback_indices = []\n",
    "    \n",
    "    \n",
    "    num_classes = list(np.unique(y_firstcol_train_vector)) #check number of classes in data. should be two\n",
    "    if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        y_firstcol_train_vector[-1] = 0 if y_firstcol_train_vector[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model1 = LogisticRegression(random_state = 0)\n",
    "    model1 = model1.fit(X_train, y_firstcol_train_vector) #train only one column at a time\n",
    "    round1_y_predictions = model1.predict(X_train)\n",
    "    \n",
    "    \n",
    "    for i in range(len(round1_y_predictions)):\n",
    "        if round1_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially for next dimension\n",
    "            firstdim_feedback_indices.append(i)\n",
    "\n",
    "    round2_X_train_input = []\n",
    "    round2_y_train_input = []\n",
    "    for cur_index in firstdim_feedback_indices:\n",
    "        round2_X_train_input.append(X_train[cur_index, :])\n",
    "        round2_y_train_input.append(y_secondcol_train_vector[cur_index])\n",
    "    \n",
    "    \n",
    "    round2_X_train_input = np.array(round2_X_train_input)\n",
    "    round2_y_train_input = np.array(round2_y_train_input)\n",
    "    \n",
    "        \n",
    "    \n",
    "    num_classes2 = list(np.unique(round2_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes2) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round2_y_train_input[-1] = 0 if round2_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    model2 = LogisticRegression(random_state = 0)\n",
    "    model2 = model2.fit(round2_X_train_input, round2_y_train_input)\n",
    "    round2_y_predictions = model2.predict(round2_X_train_input)\n",
    "    \n",
    "    \n",
    "    round3_X_train_input = []\n",
    "    round3_y_train_input = []\n",
    "    for i  in range(len(round2_y_predictions)):\n",
    "        \n",
    "        if round2_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially needed for next dinmension\n",
    "            \n",
    "            round3_X_train_input.append(round2_X_train_input[i])\n",
    "            round3_y_train_input.append(y_thirdcol_train_vector[i])\n",
    "    \n",
    "        \n",
    "    num_classes3 = list(np.unique(round3_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes3) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round3_y_train_input[-1] = 0 if round3_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model3 = LogisticRegression(random_state = 0)\n",
    "    model3 = model3.fit(round3_X_train_input, round3_y_train_input)\n",
    "    round3_y_predictions = model3.predict(round3_X_train_input)\n",
    "    \n",
    "    classification_predictions = []\n",
    "    \n",
    "    print(\"input validation =\", type(X_test), \" shape\", X_test.shape)\n",
    "    classification_predictions = model1.predict(X_test).reshape(-1,1)\n",
    "    #print(\"model 1 predictions type = \", type(cola))\n",
    "    classification_predictions = np.append(classification_predictions, model2.predict(X_test).reshape(-1,1), axis = 1)\n",
    "    classification_predictions = np.append(classification_predictions, model3.predict(X_test).reshape(-1,1), axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for given_response_vec in X_validate:\n",
    "#         print(\"asking for prediction for = \", type(given_response_vec))\n",
    "#         classifed = model1.predict(given_response_vec) + model2.predict(given_response_vec) + model3.predict(given_response_vec)\n",
    "#         print(\"prediction should be list = \", type(classified))\n",
    "#         classification_predictions.append(classified)\n",
    "    \n",
    "   #classification_predictions = np.array(classification_predictions)\n",
    "    \n",
    "    accuracy_l = []\n",
    "    for i in range(3):\n",
    "        dim_accuracy = metrics.accuracy_score(y_test[:, i], classification_predictions[:,i])\n",
    "        print(\"Accuracy on test set is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        \n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_test[:, i], classification_predictions[:,i], normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    print(metrics.classification_report(y_test, classification_predictions))\n",
    "    return accuracy_l  #accuracy for the three dimensions for a given problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ast\n",
    "\n",
    "def train_model_and_validate_specify_order_orig(given_train_df, given_test_df, golden_answers = [], given_dims_order = [], qname = \"\"):\n",
    "    \n",
    "    ydims = given_dims_order #[\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "\n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2), min_df = 2)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    y_train = given_train_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    X_test_processed_text = process_raw_features(given_test_df, pct_for_train = 1)\n",
    "    X_test = vec_fitter.transform(X_test_processed_text).toarray()\n",
    "    y_test = given_test_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_testset  = add_similarity_vector(golden_answers, X_test, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_test = np.append(X_test, distance_from_golden_vector_testset, axis = 1)\n",
    "        \n",
    "#         X_train.append(distance_from_golden_vector_trainset, axis = 1)\n",
    "#         X_validate.append(distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "  \n",
    "    \n",
    "    col1name, col2name, col3name = given_dims_order #order of the y dimensions\n",
    "    \n",
    "    y_firstcol_train_vector = given_train_df[col1name].to_numpy(dtype=int) \n",
    "    y_secondcol_train_vector = given_train_df[col2name].to_numpy(dtype=int)\n",
    "    y_thirdcol_train_vector = given_train_df[col3name].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    #potential\n",
    "    \n",
    "    firstdim_feedback_indices = []\n",
    "    seconddim_feedback_indices = []\n",
    "    thirddim_feedback_indices = []\n",
    "    \n",
    "    \n",
    "    num_classes = list(np.unique(y_firstcol_train_vector)) #check number of classes in data. should be two\n",
    "    if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        y_firstcol_train_vector[-1] = 0 if y_firstcol_train_vector[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model1 = LogisticRegression(random_state = 0)\n",
    "    model1 = model1.fit(X_train, y_firstcol_train_vector) #train only one column at a time\n",
    "    round1_y_predictions = model1.predict(X_train)\n",
    "    \n",
    "    \n",
    "    for i in range(len(round1_y_predictions)):\n",
    "        if round1_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially for next dimension\n",
    "            firstdim_feedback_indices.append(i)\n",
    "\n",
    "    round2_X_train_input = []\n",
    "    round2_y_train_input = []\n",
    "    for cur_index in firstdim_feedback_indices:\n",
    "        round2_X_train_input.append(X_train[cur_index, :])\n",
    "        round2_y_train_input.append(y_secondcol_train_vector[cur_index])\n",
    "    \n",
    "    \n",
    "    round2_X_train_input = np.array(round2_X_train_input)\n",
    "    round2_y_train_input = np.array(round2_y_train_input)\n",
    "    \n",
    "        \n",
    "    \n",
    "    num_classes2 = list(np.unique(round2_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes2) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round2_y_train_input[-1] = 0 if round2_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    model2 = LogisticRegression(random_state = 0)\n",
    "    model2 = model2.fit(round2_X_train_input, round2_y_train_input)\n",
    "    round2_y_predictions = model2.predict(round2_X_train_input)\n",
    "    \n",
    "    \n",
    "    round3_X_train_input = []\n",
    "    round3_y_train_input = []\n",
    "    for i  in range(len(round2_y_predictions)):\n",
    "        \n",
    "        if round2_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially needed for next dinmension\n",
    "            \n",
    "            round3_X_train_input.append(round2_X_train_input[i])\n",
    "            round3_y_train_input.append(y_thirdcol_train_vector[i])\n",
    "    \n",
    "        \n",
    "    num_classes3 = list(np.unique(round3_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes3) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round3_y_train_input[-1] = 0 if round3_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model3 = LogisticRegression(random_state = 0)\n",
    "    model3 = model3.fit(round3_X_train_input, round3_y_train_input)\n",
    "    round3_y_predictions = model3.predict(round3_X_train_input)\n",
    "    \n",
    "    classification_predictions = []\n",
    "    \n",
    "    print(\"input validation =\", type(X_test), \" shape\", X_test.shape)\n",
    "    classification_predictions = model1.predict(X_test).reshape(-1,1)\n",
    "    #print(\"model 1 predictions type = \", type(cola))\n",
    "    classification_predictions = np.append(classification_predictions, model2.predict(X_test).reshape(-1,1), axis = 1)\n",
    "    classification_predictions = np.append(classification_predictions, model3.predict(X_test).reshape(-1,1), axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for given_response_vec in X_validate:\n",
    "#         print(\"asking for prediction for = \", type(given_response_vec))\n",
    "#         classifed = model1.predict(given_response_vec) + model2.predict(given_response_vec) + model3.predict(given_response_vec)\n",
    "#         print(\"prediction should be list = \", type(classified))\n",
    "#         classification_predictions.append(classified)\n",
    "    \n",
    "   #classification_predictions = np.array(classification_predictions)\n",
    "    \n",
    "    accuracy_l = []\n",
    "    for i in range(3):\n",
    "        dim_accuracy = metrics.accuracy_score(y_test[:, i], classification_predictions[:,i])\n",
    "        print(\"Accuracy on test set is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        \n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_test[:, i], classification_predictions[:,i], normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    print(metrics.classification_report(y_test, classification_predictions))\n",
    "    return accuracy_l  #accuracy for the three dimensions for a given problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_validate_specify_order(given_train_df, given_test_df, golden_answers = [], given_dims_order = [], qname = \"\"):\n",
    "    \n",
    "    ydims = given_dims_order #[\"una\", \"c\", \"hl\"]\n",
    "    \n",
    "\n",
    "    X_train_processed_text = process_raw_features(given_train_df, pct_for_train = 1)\n",
    " \n",
    "    vectorizer = CountVectorizer(ngram_range = (2,2), min_df = 2)\n",
    "    vec_fitter = vectorizer.fit(X_train_processed_text)    #fit only on training data to prevent overfit\n",
    "    \n",
    "    \n",
    "    X_train = vec_fitter.transform(X_train_processed_text).toarray() #transform data into vectors and convert it to array    \n",
    "    y_train = given_train_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    X_test_processed_text = process_raw_features(given_test_df, pct_for_train = 1)\n",
    "    X_test = vec_fitter.transform(X_test_processed_text).toarray()\n",
    "    y_test = given_test_df[ydims].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    if len(golden_answers) > 0:\n",
    "    \n",
    "        distance_from_golden_vector_trainset = add_similarity_vector(golden_answers, X_train, vec_fitter)\n",
    "        distance_from_golden_vector_testset  = add_similarity_vector(golden_answers, X_test, vec_fitter)\n",
    "        \n",
    "        print(\"Original X data shape = {}, golden_answer_shape = {}\".format(X_train.shape,\n",
    "                                                                           distance_from_golden_vector_trainset.shape))\n",
    "        \n",
    "        X_train = np.append(X_train, distance_from_golden_vector_trainset, axis = 1)\n",
    "        X_test = np.append(X_test, distance_from_golden_vector_testset, axis = 1)\n",
    "        \n",
    "#         X_train.append(distance_from_golden_vector_trainset, axis = 1)\n",
    "#         X_validate.append(distance_from_golden_vector_validationset, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    labels_order = [\"Unambig\", \"Correct\", \"High level\"]\n",
    "    accuracy_l = []\n",
    "  \n",
    "    \n",
    "    col1name, col2name, col3name = given_dims_order #order of the y dimensions\n",
    "    \n",
    "    y_firstcol_train_vector = given_train_df[col1name].to_numpy(dtype=int) \n",
    "    y_secondcol_train_vector = given_train_df[col2name].to_numpy(dtype=int)\n",
    "    y_thirdcol_train_vector = given_train_df[col3name].to_numpy(dtype=int)\n",
    "    \n",
    "    \n",
    "    #potential\n",
    "    \n",
    "    firstdim_feedback_indices = []\n",
    "    seconddim_feedback_indices = []\n",
    "    thirddim_feedback_indices = []\n",
    "    \n",
    "    \n",
    "    num_classes = list(np.unique(y_firstcol_train_vector)) #check number of classes in data. should be two\n",
    "    if len(num_classes) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        y_firstcol_train_vector[-1] = 0 if y_firstcol_train_vector[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model1 = LogisticRegression(random_state = 0)\n",
    "    model1 = model1.fit(X_train, y_firstcol_train_vector) #train only one column at a time\n",
    "    round1_y_predictions = model1.predict(X_train)\n",
    "    \n",
    "    \n",
    "    for i in range(len(round1_y_predictions)):\n",
    "        if round1_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially for next dimension\n",
    "            firstdim_feedback_indices.append(i)\n",
    "\n",
    "    round2_X_train_input = []\n",
    "    round2_y_train_input = []\n",
    "    for cur_index in firstdim_feedback_indices:\n",
    "        round2_X_train_input.append(X_train[cur_index, :])\n",
    "        round2_y_train_input.append(y_secondcol_train_vector[cur_index])\n",
    "    \n",
    "    \n",
    "    round2_X_train_input = np.array(round2_X_train_input)\n",
    "    round2_y_train_input = np.array(round2_y_train_input)\n",
    "    \n",
    "        \n",
    "    \n",
    "    num_classes2 = list(np.unique(round2_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes2) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round2_y_train_input[-1] = 0 if round2_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    model2 = LogisticRegression(random_state = 0)\n",
    "    model2 = model2.fit(round2_X_train_input, round2_y_train_input)\n",
    "    round2_y_predictions = model2.predict(round2_X_train_input)\n",
    "    \n",
    "    \n",
    "    round3_X_train_input = []\n",
    "    round3_y_train_input = []\n",
    "    for i  in range(len(round2_y_predictions)):\n",
    "        \n",
    "        if round2_y_predictions[i] == 1: #no feedback needed for that dimension. feedback potentially needed for next dinmension\n",
    "            \n",
    "            round3_X_train_input.append(round2_X_train_input[i])\n",
    "            round3_y_train_input.append(y_thirdcol_train_vector[i])\n",
    "    \n",
    "        \n",
    "    num_classes3 = list(np.unique(round3_y_train_input)) #check number of classes in data. should be two\n",
    "    if len(num_classes3) == 1: #change the last y in the tuple to force training to go through - otherwise, throwing error\n",
    "        round3_y_train_input[-1] = 0 if round3_y_train_input[-1] == 1 else 0\n",
    "\n",
    "        \n",
    "    model3 = LogisticRegression(random_state = 0)\n",
    "    model3 = model3.fit(round3_X_train_input, round3_y_train_input)\n",
    "    round3_y_predictions = model3.predict(round3_X_train_input)\n",
    "    \n",
    "    classification_predictions = []\n",
    "    \n",
    "    print(\"input validation =\", type(X_test), \" shape\", X_test.shape)\n",
    "    classification_predictions = model1.predict(X_test).reshape(-1,1)\n",
    "    #print(\"model 1 predictions type = \", type(cola))\n",
    "    classification_predictions = np.append(classification_predictions, model2.predict(X_test).reshape(-1,1), axis = 1)\n",
    "    classification_predictions = np.append(classification_predictions, model3.predict(X_test).reshape(-1,1), axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for given_response_vec in X_validate:\n",
    "#         print(\"asking for prediction for = \", type(given_response_vec))\n",
    "#         classifed = model1.predict(given_response_vec) + model2.predict(given_response_vec) + model3.predict(given_response_vec)\n",
    "#         print(\"prediction should be list = \", type(classified))\n",
    "#         classification_predictions.append(classified)\n",
    "    \n",
    "   #classification_predictions = np.array(classification_predictions)\n",
    "    \n",
    "    accuracy_l = []\n",
    "    for i in range(3):\n",
    "        dim_accuracy = metrics.accuracy_score(y_test[:, i], classification_predictions[:,i])\n",
    "        print(\"Accuracy on test set is = \", dim_accuracy)\n",
    "        accuracy_l.append(dim_accuracy)\n",
    "        \n",
    "        print(\"\\n\\nConfusion Matrix:\")\n",
    "        \n",
    "        confusion_matrix = metrics.confusion_matrix(y_test[:, i], classification_predictions[:,i], normalize=\"true\")\n",
    "        print(confusion_matrix)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #uncomment next line to print the confusion matrix\n",
    "        #plot_confusion_matrix(confusion_matrix, labels_order[i] + qname,  dim_accuracy)\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    print(metrics.classification_report(y_test, classification_predictions))\n",
    "    return accuracy_l  #accuracy for the three dimensions for a given problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "best_order = None\n",
    "best_order_acc = 0\n",
    "\n",
    "for dims_order in [[\"una\", \"c\", \"hl\"], [\"una\", \"hl\" , \"c\"], [\"hl\", \"una\", \"c\"], [\"hl\", \"c\", \"una\"], [\"c\", \"hl\", \"una\"], \n",
    "                   [\"c\", \"una\", \"hl\"]]:\n",
    "    \n",
    "        \n",
    "        qids_accuracy = []\n",
    "     \n",
    "        print(\"--------------------------------------------------------------------------------------------------\\n\")\n",
    "        print(\"Cur order = {}\".format(dims_order))\n",
    "        for cur_qid in alldata_df[\"qid\"].unique().tolist():\n",
    "\n",
    "\n",
    "            cur_question_training_df = train_df[train_df[\"qid\"] == cur_qid]\n",
    "            cur_question_validation_df = validate_df[validate_df[\"qid\"] == cur_qid]\n",
    "\n",
    "            print(\"QID = \\'{}.\\'\".format(cur_qid))\n",
    "            qname_formatted = \": \" + cur_qid #format cur_qid name so it looks nice when printed with other function\n",
    "\n",
    "            q_goldenanswers = cur_question_training_df[\"example_correct_answers\"].iloc[0]\n",
    "            q_goldenanswers = ast.literal_eval(q_goldenanswers)\n",
    "\n",
    "            if type(q_goldenanswers) != list:\n",
    "                print(\"Had to convert to list\")\n",
    "                q_goldenanswers = [q_goldenanswers]\n",
    "\n",
    "\n",
    "            cur_qid_accuracy = train_model_and_validate_specify_order(cur_question_training_df, cur_question_test_df, \n",
    "                                                        qname = qname_formatted, golden_answers = q_goldenanswers, \n",
    "                                                                      given_dims_order = dims_order)\n",
    "\n",
    "            qids_accuracy.append(cur_qid_accuracy)\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "        qids_accuracy = np.array(qids_accuracy)\n",
    "        print(\"Averaging results for all qids in each of the respective dimensions\\n\")\n",
    "\n",
    "        avg_unambig_accuracy = np.mean(qids_accuracy[:, 0])\n",
    "        print(\"Avg accuracy for Unambig: {:.2f}\".format(avg_unambig_accuracy))\n",
    "\n",
    "\n",
    "        avg_corr_accuracy = np.mean(qids_accuracy[:, 1])\n",
    "        print(\"Avg accuracy for Correct column: {:.2f}\".format(avg_corr_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "        avg_highlvl_accuracy = np.mean(qids_accuracy[:, 2])\n",
    "        print(\"Avg accuracy for High-level column: {:.2f}\\n\\n\".format(avg_highlvl_accuracy))\n",
    "\n",
    "\n",
    "        avg_classifier_perf_overall = np.mean(qids_accuracy)\n",
    "        print(\"Average results across all dimensions for all qids: {:.2f}\".format(avg_classifier_perf_overall))\n",
    "    \n",
    "        if best_order_acc < avg_classifier_perf_overall:\n",
    "            best_order = dims_order\n",
    "            best_order_acc = avg_classifier_perf_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best order is {}  with accuracy of {}\".format(best_order, best_order_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([15, 6, 7]).reshape(1,-1)\n",
    "b = np.array([30, 12, 14]).reshape(1,-1)\n",
    "\n",
    "cosine_similarity(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix([1], [2], normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report([2,3], [2,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-roller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
